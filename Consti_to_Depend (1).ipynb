{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Consti_to_Depend.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwhkuuTxdqlX"
      },
      "source": [
        "#1. Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtC_E4WYcXOn"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import pprint\n",
        "import copy\n",
        "import glob\n",
        "from pprint import pprint\n",
        "from nltk.tree import Tree\n",
        "from itertools import groupby"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfCQm7U0d3Zg"
      },
      "source": [
        "# 2. Các function thông dụng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLYNuNqhd6sU"
      },
      "source": [
        "# Dùng luật để kiểm tra label có phải là head hay không\n",
        "def is_head(rule, label):\n",
        "  return re.search(rule, label)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqnJj7UteVKB"
      },
      "source": [
        "# Vì lúc tìm headword cho các address(kiểu list) của các phrase\n",
        "# thì return về dic[address]=headword nhưng dic không lưu đc dạng list -> đổi list thành string\n",
        "# Nên khi sài lại address thì cần chuyển đổi list(kiểu string) thành real list\n",
        "def str_to_list(s):\n",
        "  result = []\n",
        "  num = ''\n",
        "  for i in s:\n",
        "    if i != '[' and i !=']':\n",
        "      if i != ',':\n",
        "        if i.isnumeric():\n",
        "          num +=i\n",
        "      else: \n",
        "        result.append(int(num))\n",
        "        num = ''\n",
        "  result.append(int(num))\n",
        "  return result"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8l9byungXDu"
      },
      "source": [
        "# Lấy tất cả index của các cây con \n",
        "def get_all_index_in_tree(tree):\n",
        "  result = []\n",
        "  for index, subtree in enumerate(tree):\n",
        "    if type(subtree) != str:\n",
        "      result.append([index])\n",
        "  return result"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BAo3bsogecm"
      },
      "source": [
        "# Trả về cây con thông qua địa chỉ\n",
        "def get_subtree(subtree_address, tree):\n",
        "  if type(subtree_address) == str:\n",
        "    if subtree_address == 'root':\n",
        "      return tree\n",
        "    else:\n",
        "      subtree_address = str_to_list(subtree_address) \n",
        "  for index in subtree_address:\n",
        "    tree = tree[index]\n",
        "  return tree"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbAbYW9MgjBt"
      },
      "source": [
        "#Khám phá tất cả các phrases.\n",
        "#Sử dụng thuật toán bfs - tìm kiếm theo chiều rộng\n",
        "def get_all_subtree_address(tree):\n",
        "  queue = get_all_index_in_tree(tree)\n",
        "  explored = []\n",
        "  while queue:\n",
        "    node = queue.pop(0)\n",
        "    if node not in explored:\n",
        "      explored.append(node)\n",
        "      subtree = get_subtree(node,tree)\n",
        "      index_subtree_list = get_all_index_in_tree(subtree)\n",
        "      for index_subtree in index_subtree_list:\n",
        "        queue.append(node+index_subtree)\n",
        "  return explored"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbWWMxcrgx5N"
      },
      "source": [
        "#Do có thể xuất hiện nhiều từ giống nhau trong 1 câu\n",
        "#Nên sẽ khó xác định đâu là headword của phrase\n",
        "#-> Số hóa các từ trong câu: Mỗi từ sẽ biến đổi thành một số, số hóa bắt đầu từ số 1 \n",
        "def from_word_to_number(tree):\n",
        "  for index, leafPos in enumerate(tree.treepositions('leaves')):\n",
        "    tree[leafPos] = str(index+1)\n",
        "  return tree"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4OZhzsBi5sF"
      },
      "source": [
        "#Trong lúc đề xuất luật infer dependency label cần xét cả nhãn gốc của từ \n",
        "#Nhãn gốc là node gần nhất với node lá(từ)\n",
        "def get_POS_of_word(tree):\n",
        "  result = {}\n",
        "  for leafPos in tree.treepositions('leaves'):\n",
        "    word = tree[leafPos]\n",
        "    POS = tree[leafPos[:-1]].label()\n",
        "    result[word] = POS\n",
        "  return result"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DopZTG4fjfe2"
      },
      "source": [
        "#Trả về danh sách các nhãn gốc của từ, dùng để điền vào format CONLLU\n",
        "#Lưu ý: đối vs các nhãn NULL thì không lấy 'NONE' làm nhãn gốc\n",
        "#Vì NONE no-use trong việc relink khi NULL làm head ở phần hậu xử lý \n",
        "def get_all_POS(tree):\n",
        "  result = []\n",
        "  for leafPos in tree.treepositions('leaves'):\n",
        "    i = -1\n",
        "    POS = tree[leafPos[:i]].label().split('-')[0]\n",
        "    while POS == 'NONE':\n",
        "      i = i - 1\n",
        "      POS = tree[leafPos[:i]].label().split('-')[0]\n",
        "    result.append(POS)\n",
        "  return result"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMRzJBa1ksL0"
      },
      "source": [
        "#Follow theo Choi's guideline, lưu function_tag như đặc trưng phụ, được điền vào format CONLLU\n",
        "#Trả về function_tag của C(node cao nhất của headword)\n",
        "def get_function_tag(tree):\n",
        "  headword_of_phrase = assign_headword_for_phrase(tree)[0]\n",
        "  C_of_headword = get_C_of_headword(headword_of_phrase)\n",
        "  function_tags_of_word = {}\n",
        "  for word in tree.leaves():\n",
        "    C_label = get_subtree(C_of_headword[word], tree).label()\n",
        "    function_tags = C_label.split('-')\n",
        "    temp = []\n",
        "    for function_tag in function_tags:\n",
        "      if function_tag in ['PRD', 'CMP', 'LGS', 'CMP', 'MDP', 'TMP', 'LOC', 'MNR', 'PRP', 'ADV', 'CND', 'CNC']:\n",
        "        temp.append(function_tag)\n",
        "    if temp:\n",
        "      temp = '-'.join(temp)\n",
        "      function_tags_of_word[word] = temp\n",
        "    else:\n",
        "      function_tags_of_word[word] = '_'\n",
        "  return function_tags_of_word"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3ekdn2gln0Y"
      },
      "source": [
        "#3. Tìm headword cho các phrase\n",
        "**Các bước cụ thể:**\n",
        "\n",
        "+ Bước 1: Tìm head cho các phrase\n",
        "+ Bước 2: Loop bước 1 đi sâu xuống cây để xác định được headword\n",
        "\n",
        "**Lưu ý trong bước 1:**\n",
        "\n",
        "  Nếu số phần tử list head trả về > 1 thì xét:\n",
        "  + Nếu các label trong list head **giống nhau** thì thực hiện gán nhãn conjunction\n",
        "  + Nếu các label trong list head **khác nhau**:\n",
        "    + Xét trong khoảng từ first label đến last label trong list head có các nhãn như Cp, CONP, UCP thì gán nhãn conjunction.\n",
        "    + Nếu không phải trường hợp conjunction thì xét theo luật phụ\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtGXtiVal-Is"
      },
      "source": [
        "# Trả về list các vị trí(index) có thể làm head và list label ứng với list các index \n",
        "def finding_head_of_tree(tree):\n",
        "#Một số thay đổi:\n",
        "#đổi VP, S ở S, và thêm PRD và VP, S ở SBAR thành VP, S, SBAr\n",
        "# THÊM sQ vào S ở S và SBAR\n",
        "# SQ: VP, Sq, S -> thêm VP và S\n",
        "# thêm SPL\n",
        "# Xem SPL như S ở S và SBAR\n",
        "# Đảo -PRD trc S|SQ|SPL của S\n",
        "# tÁCH VP thành 2 loại ở S\n",
        "  head_percolation_rules = {\n",
        "    \"S\":[\"-H$\",\"^VP(-CMP|_|$)\",\"-PRD$\",\"^VP-\",\"^(S|SQ|SPL)(-|_|$)\",\"^ADJP(-|_|$)\",\"^NP(-|_|$)\"],\n",
        "    \"SBAR\":[\"-H$\",\"^VP(-|_|$)\",\"^(S|SQ|SPL)(-|_|$)\",\"^SBAR(-|_|$)\",\"^ADJP(-|_|$)\",\"^NP(-|_|$)\"],\n",
        "    \"SQ\": [\"-H$\",\"^VP(-|_|$)\",\"^QVP(-|_|$)\",\"^SQ(-|_|$)\",\"^S(-|_|$)\",\"^ADJP(-|_|$)\",\"^NP(-|_|$)\", \"^QPP(-|_|$)\"],\n",
        "    \"NP\":[\"-H$\",\"^NP(-|_|$)\",\"^(Nc|Ncs|Nu|Nun|Nt|Nq|Num|Nw|Nr|Nn)(-|_|$)\",\"^(Pd|Pp)(-|_|$)\",\"^VP(-|_|$)\"],\n",
        "    \"VP\":[\"-H$\",\"^VP(-|_|$)\",\"^(Ve|Vc|D|Vcp|Vv)(-|_|$)\",\"^(An|Aa)(-|_|$)\",\"^ADJP(-|_|$)\",\"^(Nc|Ncs|Nu|Nun|Nt|Nq|Num|Nw|Nr|Nn)(-|_|$)\",\"^NP(-|_|$)\",\"^SBAR(-|_|$)\",\"^S(-|_|$)\",\"^R(-|_|$)\",\"^RP(-|_|$)\",\"^PP(-|_|$)\"],\n",
        "    \"ADJP\":[\"-H$\",\"^ADJP(-|_|$)\",\"^(An|Aa)(-|_|$)\",\"^(Nc|Ncs|Nu|Nun|Nt|Nq|Num|Nw|Nr|Nn)(-|_|$)\",\"^S(-|_|$)\"],\n",
        "    \"RP\":[\"-H$\",\"^RP(-|_|$)\",\"^R(-|_|$)\",\"^NP(-|_|$)\"],\n",
        "    \"PP\":[\"-H$\",\"^PP(-|_|$)\",\"^Cs(-|_|$)\",\"^VP(-|_|$)\",\"^SBAR(-|_|$)\",\"^ADJP(-|_|$)\",\"^QP(-|_|$)\"],\n",
        "    \"ADJP\":[\"-H$\",\"^ADJP(-|_|$)\",\"^A(-|_|$)\",\"^N(-|_|$)\",\"^S(-|_|$)\"],\n",
        "    \"QP\":[\"-H$\",\"^QP(-|_|$)\",\"^Nq(-|_|$)\",\"^Num(-|_|$)\",\"^Nw(-|_|$)\"],\n",
        "    \"XP\":[\"-H$\",\"^XP(-|_|$)\",\"^X(-|_|$)\"],\n",
        "    \"YP\":[\"-H$\",\"^YP(-|_|$)\",\"^Y(-|_|$)\"],\n",
        "    \"MDP\":[\"-H$\",\"^MDP(-|_|$)\", \"^E(-|_|$)\", \"^(An|Aa)(-|_|$)\",\"^(Pd|Pp)(-|_|$)\", \"^R(-|_|$)\", \"^X(-|_|$)\"],\n",
        "    \"QNP\":[\"-H$\",\"^QNP(-|_|$)\",\"^NP(-|_|$)\",\"^(Nc|Ncs|Nu|Nun|Nt|Nq|Num|Nw|Nr|Nn)(-|_|$)\",\"^(Pd|Pp)(-|_|$)\"],\n",
        "    \"QADJP\":[\"-H$\",\"^QADJP(-|_|$)\",\"^(An|Aa)(-|_|$)\",\"^(Nc|Ncs|Nu|Nun|Nt|Nq|Num|Nw|Nr|Nn)(-|_|$)\",\"^(Ve|Vc|D|Vcp|Vv)(-|_|$)\",\"^(Pd|Pp)(-|_|$)\",\"^X(-|_|$)\"],\n",
        "    \"QRP\":[\"-H$\",\"^QRP(-|_|$)\",\"^(Pd|Pp)(-|_|$)\",\"^Cs(-|_|$)\",\"^X(-|_|$)\"],\n",
        "    \"QPP\":[\"-H$\",\"^QPP(-|_|$)\",\"^Cs(-|_|$)\",\"^(Pd|Pp)(-|_|$)\",\"^X(-|_|$)\"],\n",
        "    \"QXP\":[\"-H$\",\"^XP(-|_|$)\",\"^X(-|_|$)\"],\n",
        "    \"QVP\":[\"-H$\",\"^(Ve|Vc|D|Vcp|Vv)(-|_|$)\"],\n",
        "    \"UCP\":[\"-H$\"],\n",
        "    \"SPL\":[\"-H$\",\"^VP(-|_|$)\",\"^SPL(-|_|$)\", \"^ADJP(-|_|$)\",\"^NP(-|_|$)\"]\n",
        "    }\n",
        "\n",
        "  phrase_type = tree.label().split('-')[0]\n",
        "\n",
        "  head_index_result = []\n",
        "  head_label_result = []\n",
        "  if  phrase_type not in head_percolation_rules:\n",
        "    for index, element in enumerate(tree):\n",
        "      label_of_element = element.label()\n",
        "      if is_head(\"-H$\", label_of_element):\n",
        "        head_index_result.append([index])\n",
        "        head_label_result.append(label_of_element)\n",
        "\n",
        "    if head_index_result:\n",
        "      return head_index_result, head_label_result\n",
        "    else:\n",
        "      return [[0]], [tree[0].label()] \n",
        "\n",
        "  if phrase_type == 'RP':\n",
        "    for rule in head_percolation_rules['RP']:\n",
        "      if not head_index_result:\n",
        "        for index, element in zip(range(len(tree)-1, -1, -1), reversed(tree)):\n",
        "          label_of_element = element.label()\n",
        "          if is_head(rule, label_of_element):\n",
        "            head_index_result.append([index])\n",
        "            head_label_result.append(label_of_element)\n",
        "      else: \n",
        "        break\n",
        "        \n",
        "    if head_index_result:\n",
        "      return head_index_result[::-1], head_label_result[::-1]\n",
        "    else: \n",
        "      return [[0]], [tree[0].label()] \n",
        "    \n",
        "  else:\n",
        "    for rule in head_percolation_rules[phrase_type]:\n",
        "      if not head_index_result:\n",
        "        for index, element in enumerate(tree):\n",
        "          label_of_element = element.label()\n",
        "          if is_head(rule, label_of_element):\n",
        "            head_index_result.append([index])\n",
        "            head_label_result.append(label_of_element)\n",
        "      else: \n",
        "        break\n",
        "        \n",
        "    if head_index_result:\n",
        "      return head_index_result, head_label_result\n",
        "    else: \n",
        "      return [[0]], [tree[0].label()] "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EXuUj4kn2DL"
      },
      "source": [
        "# Hàm dùng trong trường hợp các label trong head list khác nhau:\n",
        "# Hàm lấy các label trong khoảng từ first label -> last label trong head list \n",
        "# Để xét coi có Cp, UCP, CONJP\n",
        "def deepen_head_list(mother_tree, tree_address, head_index_list):\n",
        "  deep_address_list = []\n",
        "  deep_label_list = []\n",
        "  first_index = head_index_list[0][0]\n",
        "  last_index = head_index_list[-1][0]\n",
        "  for index in range(first_index, last_index+1):\n",
        "    if tree_address != 'root':\n",
        "      subtree_address = tree_address + [index]\n",
        "    else:\n",
        "      subtree_address = [index]\n",
        "    deep_address_list.append(subtree_address)\n",
        "    deep_label_list.append(get_subtree(subtree_address, mother_tree).label())\n",
        "  return deep_address_list, deep_label_list"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHEICEJ8xELa"
      },
      "source": [
        "# Dán nhãn conjunction \n",
        "def get_conjunction(P_address, C_address_list, C_label_list):\n",
        "  P_of_C_dic = {}\n",
        "  previous_C_address = str(C_address_list[0])\n",
        "  for C_address, C_label in zip(C_address_list[1:], C_label_list[1:]):\n",
        "    if C_label == 'PU':\n",
        "      P_of_C_dic[str(C_address)] = (previous_C_address, 'PUNCT')\n",
        "    elif re.search('^(Cp|CONJP)', C_label):\n",
        "      P_of_C_dic[str(C_address)] = (previous_C_address, 'CC')\n",
        "    else:\n",
        "      P_of_C_dic[str(C_address)] = (previous_C_address, 'CONJ')\n",
        "    if (C_label != 'PU') and (C_label != 'Cp') and ('CONJP' not in C_label):\n",
        "      previous_C_address = str(C_address)\n",
        "  return P_of_C_dic"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpcyw_ul_f5L"
      },
      "source": [
        "def has_SPL_and_S(unique):\n",
        "  has_S = False\n",
        "  has_SPL = False\n",
        "  for element in unique:\n",
        "    if re.search('^S(-|$)', element):\n",
        "      has_S = True\n",
        "    elif re.search('^SPL(-|$)', element):\n",
        "      has_SPL = True\n",
        "  if has_S and has_SPL:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F52Tn7CIxHv5"
      },
      "source": [
        "# Kiểm tra có phải là trường hợp conj hay không\n",
        "def is_conjunction(C_label_list):\n",
        "\n",
        "  unique = set(C_label_list)\n",
        "  if len(unique) == 3:\n",
        "    if ('PU' in unique) and ((('Cp' in unique) or ('CONJP' in unique)) and (('Cp' != C_label_list[0]) or ('CONJP' != C_label_list[0]))):\n",
        "      return True\n",
        "    elif (('PU' in unique) or ('Cp' in unique) or ('CONJP' in unique)) and has_SPL_and_S(unique):\n",
        "      return True\n",
        "  elif len(unique) == 2:\n",
        "    if ('PU' in unique) or ((('Cp' in unique) or ('CONJP' in unique)) and (('Cp' != C_label_list[0]) or ('CONJP' != C_label_list[0]))):\n",
        "      return True\n",
        "    elif has_SPL_and_S(unique):\n",
        "      return True\n",
        "  elif len(unique) == 1:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "def has_same_phrase_type(C_label_list):\n",
        "  phrase_type_set= set()\n",
        "  for C_label in C_label_list:\n",
        "    phrase_type = C_label.split('-')[0]\n",
        "    phrase_type_set.add(phrase_type)\n",
        "    if len(phrase_type_set) == 2:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "#Dùng xác định head khi head list > 1\n",
        "def identify_head(tree, P_address, C_address_list, C_label_list, head_C_address_list, head_C_label_list):\n",
        "\n",
        "  if is_conjunction(C_label_list):\n",
        "    P_of_C_dic = get_conjunction(P_address, C_address_list, C_label_list)\n",
        "    return [C_address_list[0], P_of_C_dic]\n",
        "\n",
        "  if has_same_phrase_type(head_C_label_list):\n",
        "    if (('Cp' in C_label_list) or ('CONJP' in C_label_list)) and (C_label_list[0] != 'Cp') and (C_label_list[0] != 'CONJP'):\n",
        "      P_of_C_dic = get_conjunction(P_address, C_address_list, C_label_list)\n",
        "      return [C_address_list[0], P_of_C_dic]\n",
        "    else:\n",
        "      first_element = head_C_address_list[0]\n",
        "      if first_element[-1] >= 1:\n",
        "        pre_address_of_head_C_address_list = first_element[:-1] + [first_element[-1]-1] \n",
        "        pre_subtree = get_subtree(pre_address_of_head_C_address_list, tree)\n",
        "        pre_subtree_label = pre_subtree.label()\n",
        "        if re.search('^(Cp|CONJP)', pre_subtree_label):\n",
        "          P_of_C_dic = get_conjunction(P_address, C_address_list, C_label_list)\n",
        "          return [C_address_list[0], P_of_C_dic]\n",
        "\n",
        "    for head_C_address, head_C_label in zip(head_C_address_list, head_C_label_list):\n",
        "      if '-' not in head_C_label:\n",
        "        return [head_C_address]\n",
        "\n",
        "    for head_C_address, head_C_label in zip(head_C_address_list, head_C_label_list):\n",
        "      if '-SBJ' not in head_C_label:\n",
        "        return [head_C_address]\n",
        "  else:\n",
        "    if ('Cp' in C_label_list) and (C_label_list[0] != 'Cp'):\n",
        "      P_of_C_dic = get_conjunction(P_address, C_address_list, C_label_list)\n",
        "      return [C_address_list[0], P_of_C_dic]\n",
        "\n",
        "    else:\n",
        "      P_phrase_type = get_subtree(P_address, tree).label().split('-')[0]\n",
        "      head_exception_rules = {\n",
        "          \"NP\":[\"^(Nn_swsp|Nn_w)(-|$)\",\"^(Nn|Nu|Nun|Nt)(-|$)\",\"^(Num|Nq|Nr)(-|$)\", \"^(Pd|Pp)\"],\n",
        "          \"ADJP\":[\"^(Aa)\"],\n",
        "          \"QP\":[\"^Nq(-|$)\",\"^Num(-|$)\"],\n",
        "          \"Nn_swsp\":[\"^(Ncs|Nc)(-|$)\"],\n",
        "          \"VP\":[\"^(Ve|Vc|D|Vcp|Vv)(-|$)\"],\n",
        "          \"S\":[\"^(S|SQ|SPL)($)\", \"^(ADJP)\"],\n",
        "          \"SBAR\":[\"^(S|SQ|SPL)($)\"],\n",
        "          \"PP\":[\"^(Cs)\"],\n",
        "          \"VP\":[\"^(Vv|Vc|Ve)\",\"^(Nq)\"] # Luật theo cây bị gán sai :))\n",
        "\n",
        "      }\n",
        "      for rule in head_exception_rules[P_phrase_type]:\n",
        "              for head_C_address, head_C_label  in zip(head_C_address_list, head_C_label_list):\n",
        "                if is_head(rule, head_C_label):\n",
        "                  return [head_C_address]\n",
        "  return \"Nope\"      "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9V2zeNIxeH1"
      },
      "source": [
        "# Trả về list các phrase có chung headword\n",
        "def from_phrase_to_headword(mother_tree, tree, tree_address):\n",
        "  phrase_to_headword = [tree_address]\n",
        "  if tree_address != 'root':\n",
        "    tree = get_subtree(tree_address, mother_tree)\n",
        "  P_of_C_dic = {}\n",
        "  while type(tree[0]) != str:\n",
        "      head_index_list, head_label_list = finding_head_of_tree(tree)\n",
        "      \n",
        "      \n",
        "      if len(head_index_list) == 1:\n",
        "        if tree_address != 'root':\n",
        "          tree_address = tree_address + head_index_list[0]\n",
        "        else:\n",
        "          tree_address = head_index_list[0]\n",
        "        tree = get_subtree(tree_address, mother_tree)\n",
        "        phrase_to_headword.append(tree_address)\n",
        "      else:   \n",
        "        address_list, label_list = deepen_head_list(mother_tree, tree_address, head_index_list)\n",
        "        head_address_list = []\n",
        "        for head_index in head_index_list:\n",
        "          if tree_address != 'root':\n",
        "            head_address_list.append(tree_address + head_index)\n",
        "          else:\n",
        "            head_address_list.append(head_index)\n",
        "        result = identify_head(mother_tree, tree_address, address_list, label_list, head_address_list, head_label_list)\n",
        "        tree_address = result[0]\n",
        "        #print(tree_address, address_list, label_list)\n",
        "        tree = get_subtree(tree_address, mother_tree)\n",
        "        phrase_to_headword.append(tree_address)\n",
        "        if len(result) == 2:\n",
        "          P_of_C_dic.update(result[1])  \n",
        "  phrase_to_headword.append(tree[0])\n",
        "  return [phrase_to_headword, P_of_C_dic]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK9pgpDnxipk"
      },
      "source": [
        "def assign_headword_for_phrase(tree):\n",
        "  \n",
        "  P_of_C_dic = {}\n",
        "  headword_of_phrase = {}\n",
        "  phrase_address_list = ['root'] + get_all_subtree_address(tree)\n",
        "  \n",
        "  #Tìm head\n",
        "  for phrase_address in phrase_address_list:\n",
        "    if str(phrase_address) not in headword_of_phrase:\n",
        "      if phrase_address != 'root': \n",
        "        subtree = get_subtree(phrase_address, tree)\n",
        "      else:    \n",
        "        subtree = tree\n",
        "      if type(subtree[0]) != str:\n",
        "        result = from_phrase_to_headword(tree, subtree, phrase_address)       \n",
        "        phrase_to_headword = result[0][:-1]\n",
        "        headword = result[0][-1] \n",
        "        P_of_C_dic.update(result[1])\n",
        "        for head_phrase_address in phrase_to_headword:\n",
        "          headword_of_phrase[str(head_phrase_address)] = headword\n",
        "      else:\n",
        "        headword_of_phrase[str(phrase_address)] = subtree[0]\n",
        "\n",
        "  for phrase_address in get_all_subtree_address(tree):\n",
        "    subtree = get_subtree(phrase_address, tree)\n",
        "    label = subtree.label().split('-')[0]\n",
        "    if label == 'UCP':\n",
        "      C_address_list = []\n",
        "      C_label_list = []\n",
        "      for index_subtree in range(len(subtree)):\n",
        "        subtree_address = phrase_address+[index_subtree]\n",
        "        subtree_label = get_subtree(subtree_address, tree).label() \n",
        "        C_address_list.append(subtree_address)\n",
        "        C_label_list.append(subtree_label)\n",
        "      P_of_C_dic.update(get_conjunction(phrase_address, C_address_list, C_label_list))\n",
        "  return [headword_of_phrase, P_of_C_dic]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YylmzMRoSoCZ",
        "outputId": "6f9a2a94-b6d8-4df6-e7e6-3007505f7ec6"
      },
      "source": [
        "tree = Tree.fromstring('(S (PP-LOC (Cs-H Trong) (NP (Nn-H khoảnh) (Nn đất) (NP (QP (R khoảng) (Num-H 100)) (Nu-H m2)) (VP (ID-H che_mưa_che_nắng) (PP-MNR (Cs-H bằng) (NP (ADJP (Aa-H nhiều)) (Nn_swsp (Nc-H-1 tấm) (Nn bạt)) (VP (Vv *P*) (VP (Vv-H chắp_vá) (NP-DOB (Nn *D*-1))))))) (Pd ấy))) (NP-PRD (Nn-H bụi)) (ADJP-PRD (Aa-H mù_mịt)) (PU .))')\n",
        "tree.pretty_print()\n",
        "# tree = Tree.fromstring('(S (NP-SBJ (Nn-H Câu_chuyện) (Vv đánh_ghen) (NP-TMP (Nt-H ngày_mai))) (VP (R càng) (Vv-H chứng_tỏ) (NP-DOB (Nn-H điều) (Pd đó))) (PU ,) (NP-TMP (Nt-H khi) (SBAR (Cs *0*) (S (NP-SBJ (Num một) (Nn_swsp (Nc-H người) (Nn vợ)) (ADJP (Aa-H thảo_hiền))) (VP (Vv-H hoá) (VP-CMP (Vv-H thành) (NP-CMP (Num một) (Nn-H hoạn_thư) (NP (NP (Nn-H kế) (ADJP (Aa-H độc))) (PU ,) (NP (Nn-H mưu) (ADJP (Aa-H sâu)))))))))) (PU ...))')\n",
        "from_word_to_number(tree)\n",
        "assign_headword_for_phrase(tree)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                               S                                                                     \n",
            "                    ___________________________________________|___________________________________________________________________   \n",
            "                 PP-LOC                                                                                             |       |      | \n",
            "   ________________|_____________________________________                                                           |       |      |  \n",
            "  |                                                      NP                                                         |       |      | \n",
            "  |      ________________________________________________|_____________________________________________________     |       |      |  \n",
            "  |     |     |               |                          VP                                                    |    |       |      | \n",
            "  |     |     |               |                __________|_____                                                |    |       |      |  \n",
            "  |     |     |               |               |              PP-MNR                                            |    |       |      | \n",
            "  |     |     |               |               |           _____|____________________                           |    |       |      |  \n",
            "  |     |     |               |               |          |                          NP                         |    |       |      | \n",
            "  |     |     |               |               |          |      ____________________|_________                 |    |       |      |  \n",
            "  |     |     |               |               |          |     |              |               VP               |    |       |      | \n",
            "  |     |     |               |               |          |     |              |          _____|_____           |    |       |      |  \n",
            "  |     |     |               NP              |          |     |              |         |           VP         |    |       |      | \n",
            "  |     |     |           ____|____           |          |     |              |         |      _____|____      |    |       |      |  \n",
            "  |     |     |          QP        |          |          |    ADJP         Nn_swsp      |     |        NP-DOB  |  NP-PRD ADJP-PRD  | \n",
            "  |     |     |     _____|____     |          |          |     |       _______|_____    |     |          |     |    |       |      |  \n",
            " Cs-H  Nn-H   Nn   R        Num-H Nu-H       ID-H       Cs-H  Aa-H  Nc-H-1          Nn  Vv   Vv-H        Nn    Pd  Nn-H    Aa-H    PU\n",
            "  |     |     |    |          |    |          |          |     |      |             |   |     |          |     |    |       |      |  \n",
            "Trong khoảnh đất khoảng      100   m2  che_mưa_che_nắng bằng nhiều   tấm           bạt *P* chắp_vá     *D*-1   ấy  bụi    mù_mịt   . \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'[0, 0]': '1',\n",
              "  '[0, 1, 0]': '2',\n",
              "  '[0, 1, 1]': '3',\n",
              "  '[0, 1, 2, 0, 0]': '4',\n",
              "  '[0, 1, 2, 0, 1]': '5',\n",
              "  '[0, 1, 2, 0]': '5',\n",
              "  '[0, 1, 2, 1]': '6',\n",
              "  '[0, 1, 2]': '6',\n",
              "  '[0, 1, 3, 0]': '7',\n",
              "  '[0, 1, 3, 1, 0]': '8',\n",
              "  '[0, 1, 3, 1, 1, 0, 0]': '9',\n",
              "  '[0, 1, 3, 1, 1, 0]': '9',\n",
              "  '[0, 1, 3, 1, 1, 1, 0]': '10',\n",
              "  '[0, 1, 3, 1, 1, 1, 1]': '11',\n",
              "  '[0, 1, 3, 1, 1, 1]': '10',\n",
              "  '[0, 1, 3, 1, 1, 2, 0]': '12',\n",
              "  '[0, 1, 3, 1, 1, 2, 1, 0]': '13',\n",
              "  '[0, 1, 3, 1, 1, 2, 1, 1, 0]': '14',\n",
              "  '[0, 1, 3, 1, 1, 2, 1, 1]': '14',\n",
              "  '[0, 1, 3, 1, 1, 2, 1]': '13',\n",
              "  '[0, 1, 3, 1, 1, 2]': '13',\n",
              "  '[0, 1, 3, 1, 1]': '10',\n",
              "  '[0, 1, 3, 1]': '8',\n",
              "  '[0, 1, 3]': '7',\n",
              "  '[0, 1, 4]': '15',\n",
              "  '[0, 1]': '2',\n",
              "  '[0]': '1',\n",
              "  '[1, 0]': '16',\n",
              "  '[1]': '16',\n",
              "  '[2, 0]': '17',\n",
              "  '[2]': '17',\n",
              "  '[3]': '18',\n",
              "  'root': '17'},\n",
              " {}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeCyefMVeLnL"
      },
      "source": [
        "#4. Dán nhãn \n",
        "Các bước cụ thể:\n",
        "+ Bước 1: Xác định C(node cao nhất của headword) và P(node parent của C)\n",
        "+ Bước 2: Viết luật dán nhãn được suy ra từ label của C và P\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mifyOIfeXCy"
      },
      "source": [
        "# Lấy C của word\n",
        "def get_C_of_headword(headword_of_phrase):\n",
        "  duplicate_headword_of_phrase = {}\n",
        "  duplicate_headword_of_phrase.update(headword_of_phrase)\n",
        "  del duplicate_headword_of_phrase['root']\n",
        "  merge = {}\n",
        "  for key, value in sorted(duplicate_headword_of_phrase.items()):\n",
        "      merge.setdefault(value, []).append(key)\n",
        "  C ={}\n",
        "  for headword in merge:\n",
        "    C[headword]=min(merge[headword], key=len)\n",
        "  return C"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx5F5gx8fUXa"
      },
      "source": [
        "# Lấy P của C\n",
        "def get_P_of_C(phrase_address, root_address):\n",
        "  if not str_to_list(phrase_address)[:-1]:\n",
        "    return root_address\n",
        "  return str(str_to_list(phrase_address)[:-1])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F55gILhPfVyC"
      },
      "source": [
        "# Dán nhãn dựa trên các Luật\n",
        "def get_dependency_relation(P_address, C_address, P_index, tree):\n",
        "  #get C_label and P_label\n",
        "  C_tree = get_subtree(C_address, tree)\n",
        "  C = C_tree.label()\n",
        "  P = get_subtree(P_address, tree).label()\n",
        "  \n",
        "  POS_of_word = get_POS_of_word(tree)\n",
        "  p = POS_of_word[P_index]\n",
        "  # Nếu C là UCP thì relation sẽ đc quyết bởi POS trái nhất trong cây UCP\n",
        "  if 'UCP' in C:\n",
        "    C = C_tree[0].label()\n",
        "\n",
        "  #Luật\n",
        "  if has_SBJ(C):\n",
        "    return has_SBJ(C)\n",
        "  \n",
        "  if is_ADJUNCT(C):\n",
        "    return is_ADJUNCT(C)\n",
        "  \n",
        "  if is_PARATAXIS(C):\n",
        "    return is_PARATAXIS(C)\n",
        "  \n",
        "  if is_VOCATIVE(C):\n",
        "    return is_VOCATIVE(C)\n",
        "\n",
        "  if is_NP_ADVMOD(P, C):\n",
        "    return is_NP_ADVMOD(P, C)\n",
        "\n",
        "  if is_ADJP_ADVMOD(P, C):\n",
        "    return is_ADJP_ADVMOD(P, C)\n",
        "\n",
        "  if is_VMOD_or_RCMOD(P, C):\n",
        "    return is_VMOD_or_RCMOD(P, C)\n",
        "\n",
        "  if is_NUM(P, C):\n",
        "    return is_NUM(P, C)\n",
        "\n",
        "  if is_NN(P, C):\n",
        "    return is_NN(P, C)\n",
        "\n",
        "  if is_PREP(C):\n",
        "    return is_PREP(C)\n",
        "  \n",
        "  if is_POBJ_or_PCOMP(P, C):\n",
        "    return is_POBJ_or_PCOMP(P, C)\n",
        "    \n",
        "  if is_PUNCT(C):\n",
        "    return is_PUNCT(C)\n",
        "\n",
        "  if is_CLF_or_NN(P, p):\n",
        "    return is_CLF_or_NN(P, p)\n",
        "\n",
        "  if is_AMOD(P, C):\n",
        "    return is_AMOD(P, C)\n",
        "  \n",
        "  if is_NUMBER_or_QUANTMOD(P, C):\n",
        "    return is_NUMBER_or_QUANTMOD(P, C)\n",
        "  \n",
        "  if is_NN(P, C):\n",
        "    return is_NN(P, C)\n",
        "  \n",
        "  if is_DET(P, C):\n",
        "    return is_DET(P, C)\n",
        "\n",
        "  if is_ATTR(p, C):\n",
        "    return is_ATTR(p, C)\n",
        "\n",
        "  if is_IOBJ(P, C):\n",
        "    return is_IOBJ(P, C)\n",
        "  \n",
        "  if is_OBJ_or_NP_ADVMOD(P, C):\n",
        "    return is_OBJ_or_NP_ADVMOD(P, C)\n",
        "\n",
        "  if is_CCOMP_or_XCOMP_or_ADVCL(P, C, C_tree):\n",
        "    return is_CCOMP_or_XCOMP_or_ADVCL(P, C, C_tree)\n",
        "  \n",
        "  if is_ACOMP(P, C):\n",
        "    return is_ACOMP(P, C)\n",
        "  \n",
        "  if is_ADVCL(P, C):\n",
        "    return is_ADVCL(P, C)\n",
        "\n",
        "  if is_SINO(P):\n",
        "    return is_SINO(P)\n",
        "\n",
        "  if is_INTJ(C):\n",
        "    return is_INTJ(C)\n",
        "  \n",
        "  if is_CC(C):\n",
        "    return is_CC(C)\n",
        "\n",
        "  if is_MARK(C):\n",
        "    return is_MARK(C)\n",
        "#Luật phụ\n",
        "  if is_NSUBJ(C, P):\n",
        "    return is_NSUBJ(C, P)\n",
        "\n",
        "  return 'DEP'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdNGzc8zfiLj"
      },
      "source": [
        "## Các luật chuyển đổi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agop9uJ-fv6S"
      },
      "source": [
        "# Hàm dùng để xác định xem  coi S có chủ ngữ không để suy ra CCOMP or XCOMP\n",
        "def has_empty_subject(tree):\n",
        "  if 'SBAR' in tree.label():\n",
        "    for subtree in tree:\n",
        "      if re.search('^S(-|$)', subtree.label()):\n",
        "        for sub_subtree in subtree:\n",
        "          if 'NP-SBJ' in sub_subtree.label() and 'NONE' in sub_subtree[0].label():\n",
        "            return True\n",
        "        return False\n",
        "    return False \n",
        "  elif re.search('^S(-|$)', tree.label()):\n",
        "    for subtree in tree:\n",
        "      if 'NP-SBJ' in subtree.label() and 'NONE' in subtree[0].label():\n",
        "        return True\n",
        "    return False\n",
        "  return False"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seHZc3CYf6Ub"
      },
      "source": [
        "# Hàm dùng để xem coi cây có thành phần POS mà mình muốn hay không\n",
        "# Ví dụ xét coi cây có nhãn VP để suy ra CCOMP or XCOMP\n",
        "def has_POS(tree, POS):\n",
        "  if 'SBAR' in tree.label():\n",
        "    for subtree in tree:\n",
        "      if re.search('^S(-|$)', subtree.label()):\n",
        "        for sub_subtree in subtree:\n",
        "          label_sub_subtree = sub_subtree.label()\n",
        "          if re.search('^{}(-|$)'.format(POS), label_sub_subtree):\n",
        "            return True\n",
        "        return False\n",
        "    return False \n",
        "\n",
        "  elif re.search('^S(-|$)', tree.label()):\n",
        "    for subtree in tree:\n",
        "      label_subtree = subtree.label()\n",
        "      if re.search('^{}(-|$)'.format(POS), label_subtree):\n",
        "        return True\n",
        "    return False\n",
        "  return False"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsjvTF3Vf-4q"
      },
      "source": [
        "#S(-|$) phân biệt vs SBAR\n",
        "def has_SBJ(C):\n",
        "  if 'NP-SBJ' in C:\n",
        "    return 'NSUBJ'\n",
        "  elif 'ADJP-SBJ' in C:\n",
        "    return 'ASUBJ'\n",
        "  elif 'VP-SBJ' in C:\n",
        "    return 'VSUBJ'\n",
        "  elif ('S-SBJ' in C) or ('SPL-SBJ' in C):\n",
        "    return 'CSUBJ'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_NSUBJ(C, P):\n",
        "  if re.search('^S$', P) and re.search('^NP$', C):\n",
        "    return 'NSUBJ'\n",
        "  else:\n",
        "    return False\n",
        "# def is_VMOD_or_RCMOD(P, C):#Ve|Vc|D|Vcp|Vv\n",
        "#   if re.search('^(VP)', C):\n",
        "#     if re.search('^(VP|ADJP|S)', P):\n",
        "#       return 'VMOD'\n",
        "#     elif re.search('^(NP|QNP)', P):\n",
        "#       return 'RCMOD'\n",
        "#     else:\n",
        "#       return False\n",
        "#   elif re.search('^(NP)', P) and re.search('^(Vv)', C) :\n",
        "#     return 'VMOD'\n",
        "#   else:\n",
        "#     return False\n",
        "\n",
        "def is_VMOD_or_RCMOD(P, C):#Ve|Vc|D|Vcp|Vv\n",
        "  if re.search('^(VP|ADJP|S)', P):\n",
        "    if re.search('^(VP|Ve|Vc|D|Vcp|Vv)', C):\n",
        "      return 'VMOD'\n",
        "    else:\n",
        "      return False\n",
        "  elif re.search('^(NP|QNP)', P):\n",
        "    if re.search('^(VP)', C):\n",
        "      return 'RCMOD'\n",
        "    elif re.search('^(Ve|Vc|D|Vcp|Vv)', C):\n",
        "      return 'VMOD'\n",
        "    else:\n",
        "      return False\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_NUM(P, C):\n",
        "  if re.search('^(NP|QNP|Nn)', P) and re.search('^(Num|QP)', C):\n",
        "    return 'NUM'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_NN(P, C):\n",
        "  if re.search('^(NP)', P) and re.search('^(NP|ID)', C):\n",
        "    return 'NN'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_PREP(C):\n",
        "  if re.search('^(PP|QPP)', C):\n",
        "    return 'PREP'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_POBJ_or_PCOMP(P, C):\n",
        "  if re.search('^(PP|QPP)', P):\n",
        "    if re.search('^(NP)', C):\n",
        "      return 'POBJ'\n",
        "    else:\n",
        "      return 'PCOMP'\n",
        "  else:\n",
        "    return False\n",
        "    \n",
        "def is_PUNCT(C):\n",
        "  if re.search('^(PU|LBRK|RBRK)', C):\n",
        "    return 'PUNCT'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_CLF_or_NN(P, p):\n",
        "  if re.search('^(Nn_swsp)', P):\n",
        "    if re.search('^(Nc|Ncs)', p):\n",
        "      return 'CLF'\n",
        "    else:\n",
        "      return 'NN'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_AMOD(P, C):\n",
        "  if re.search('^(NP|QNP)', P) and re.search('^(Aa|An|ADJP)', C): \n",
        "    return 'AMOD'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_NUMBER_or_QUANTMOD(P, C):\n",
        "  if re.search('^(QP)', P):\n",
        "    if re.search('^(Num|Nq)', C):\n",
        "      return 'NUMBER'\n",
        "    else:\n",
        "      return 'QUANTMOD'\n",
        "  else: \n",
        "    return False \n",
        "\n",
        "def is_NN(P, C):\n",
        "  if re.search('^(NP|QNP)', P) and re.search('^(NP|Nr|Nt|Nu|Nun|Nn)', C):\n",
        "    return 'NN'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_DET(P, C):\n",
        "  if re.search('^(NP|QNP)', P) and re.search('^(Nw|Nq|Pd|Pp)', C):\n",
        "    return 'DET' \n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_ATTR(p, C):\n",
        "  if re.search('^(Vc)', p) and re.search('^(NP|QNP)(-CMP)', C):\n",
        "    return 'ATTR' \n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_IOBJ(P, C):\n",
        "  if re.search('^(VP)', P) and re.search('^(NP-IOB)', C):\n",
        "    return 'IOBJ'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_OBJ_or_NP_ADVMOD(P, C):\n",
        "  if re.search('^(VP)', P) and re.search('^(NP)(-MNR)', C):\n",
        "    return 'NP_ADVMOD'\n",
        "  elif (re.search('^(VP|ADJP)', P) and re.search('^(NP|QNP|Nn)', C)) or ('-DOB' in C):\n",
        "    return 'OBJ'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_CCOMP_or_XCOMP_or_ADVCL(P, C, C_tree):\n",
        "  # if re.search('^(NP)', P):  \n",
        "  #   if re.search('^(S)(-CMP|$)', C): # phân biệt SBAR\n",
        "  #     return 'CCOMP'\n",
        "  #   elif re.search('^(SBAR)(-CMP|$)', C) and C_tree[0].label() == 'Cs':\n",
        "  #     return 'CCOMP'\n",
        "  #   else:\n",
        "  #     return 'False'\n",
        "  if re.search('^(VP|NP|ADJP|SQ|S|QVP)', P):\n",
        "    if re.search('^(SQ|SPL)(-|$)', C):\n",
        "      return 'CCOMP'\n",
        "    elif re.search('^(S)(-[0-9]|-CMP|$)', C):\n",
        "      if has_empty_subject(C_tree) and has_POS(C_tree, 'VP'):\n",
        "        return 'XCOMP'\n",
        "      else:\n",
        "        return 'CCOMP'\n",
        "    elif re.search('^(SBAR)(-[0-9]|-CMP|$)', C):\n",
        "      if has_empty_subject(C_tree) and has_POS(C_tree, 'VP'):\n",
        "        return 'XCOMP'\n",
        "      else:\n",
        "        return 'CCOMP'\n",
        "    elif re.search('^(SBAR)(-PRP)', C):\n",
        "      return 'ADVCL'\n",
        "    else:\n",
        "      return False\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_ADJUNCT(C):\n",
        "  if re.search('^(R|RP|QRP)(-|$)', C):\n",
        "    return 'ADJUNCT'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_NP_ADVMOD(P, C):\n",
        "  if re.search('^((S)(-|$)|SPL|NP|ADJP|VP|SQ)', P) and re.search('^(NP)(-TMP|-MNR|-ADV|-LOC)', C):\n",
        "    return 'NP_ADVMOD'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_ADJP_ADVMOD(P, C):\n",
        "  if re.search('^(VP|S(-|$)|SPL)', P) and re.search('^(ADJP)(-MNR|-ADV|-TMP|-MDP|-LOC|-PRD)', C):\n",
        "      return 'ADJP_ADVMOD'\n",
        "  elif re.search('^(ADJP)', P) and re.search('^(ADJP)', C):\n",
        "    return 'ADJP_ADVMOD'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_ACOMP(P, C):\n",
        "  if re.search('^(VP)', P) and re.search('^(ADJP)(-CMP|$)', C):\n",
        "    return 'ACOMP'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_ADVCL(P, C):\n",
        "  if re.search('^(S)(-CND|-PRN|-TMP|-PRP|-ADV|-MNR|-CNC)', C):\n",
        "    return 'ADVCL'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_PARATAXIS(C):\n",
        "  if '-PRN'in C:\n",
        "    return 'PARATAXIS'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_SINO(P):\n",
        "  if '_w' in P:\n",
        "    return 'SINO'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_INTJ(C):\n",
        "  if re.search('^(E|M)', C):\n",
        "    return 'INTJ'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_CC(C):\n",
        "  if re.search('^(Cp|CONJP)', C):\n",
        "    return 'CC'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_MARK(C):\n",
        "  if C == 'Cs':\n",
        "    return 'MARK'\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def is_VOCATIVE(C):\n",
        "  if '-VOC'in C:\n",
        "    return 'VOCATIVE'\n",
        "  else:\n",
        "    return False"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-DGdi1Ng8iy"
      },
      "source": [
        "##Hàm main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9-OB4KLg-cq"
      },
      "source": [
        "def get_all_relation(tree):\n",
        "  tree = from_word_to_number(tree)\n",
        "  \n",
        "  result = assign_headword_for_phrase(tree)\n",
        "\n",
        "  headword_of_phrase = result[0]\n",
        "  C_of_headword = get_C_of_headword(headword_of_phrase)\n",
        " \n",
        "  P_of_C = result[1]\n",
        "  relation_dic = {}\n",
        "  root_address = C_of_headword[headword_of_phrase['root']]\n",
        "  \n",
        "  P_index = '0'\n",
        "  relation = 'ROOT'\n",
        "  C_index = headword_of_phrase['root']\n",
        "  relation_dic[C_index] = [P_index, relation]\n",
        "  \n",
        "\n",
        "  for C_index in tree.leaves():\n",
        "    if C_index not in relation_dic:\n",
        "      \n",
        "      C_address = C_of_headword[C_index]\n",
        "      if C_address in P_of_C:\n",
        "        P_address = P_of_C[C_address][0]\n",
        "        relation = P_of_C[C_address][1]\n",
        "        P_index = headword_of_phrase[P_address]\n",
        "        relation_dic[C_index] = [P_index, relation]\n",
        "      else:\n",
        "        P_address = get_P_of_C(C_address, root_address)\n",
        "        P_index = headword_of_phrase[P_address] \n",
        "        relation = get_dependency_relation(P_address, C_address, P_index, tree)\n",
        "        relation_dic[C_index] = [P_index, relation]\n",
        "  return relation_dic"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IzyAnCQMd2X",
        "outputId": "e89e7cac-d08a-4dd1-beb0-d672432b1c10"
      },
      "source": [
        "get_all_relation(tree)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': ['17', 'PREP'],\n",
              " '10': ['8', 'POBJ'],\n",
              " '11': ['10', 'CLF'],\n",
              " '12': ['13', 'VMOD'],\n",
              " '13': ['10', 'RCMOD'],\n",
              " '14': ['13', 'OBJ'],\n",
              " '15': ['2', 'DET'],\n",
              " '16': ['17', 'OBJ'],\n",
              " '17': ['0', 'ROOT'],\n",
              " '18': ['17', 'PUNCT'],\n",
              " '2': ['1', 'POBJ'],\n",
              " '3': ['2', 'NN'],\n",
              " '4': ['5', 'ADJUNCT'],\n",
              " '5': ['6', 'NUM'],\n",
              " '6': ['2', 'NN'],\n",
              " '7': ['2', 'RCMOD'],\n",
              " '8': ['7', 'PREP'],\n",
              " '9': ['10', 'AMOD']}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NftWKhYfhd1K"
      },
      "source": [
        "#Hậu xử lý"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9zDv21Dh6kK"
      },
      "source": [
        "## Hàm tạo file thông dụng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0tG02rRhihz"
      },
      "source": [
        "def to_oneline(folder, filename):\n",
        "  with open(f'/content/NIIVTB-1/{folder}/{filename}','r',encoding='utf8') as reader:\n",
        "    regex = r'(?<=<s>).+?(?=</s>)'\n",
        "    pattern = re.compile(regex,re.M|re.I|re.S)\n",
        "    data = reader.readlines()\n",
        "    data = ''.join(data)\n",
        "    sentences = re.findall(pattern=pattern,string=data)\n",
        "  with open(f'/content/OneLine/{folder}/[Line]{filename}','w',encoding='utf8') as writer:\n",
        "    for sentence in sentences:\n",
        "      writer.write(re.sub(re.compile('[\\s\\t\\n]+',re.I|re.M),' ',sentence).strip())\n",
        "      writer.write('\\n')\n",
        "      "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW9_FCYriGNZ"
      },
      "source": [
        "## Hàm thông dụng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bscZCGebiM0n"
      },
      "source": [
        "# Trả về cây dependency (dạng list)\n",
        "def get_dependency_tree_list(folder, filename):\n",
        "  #exception_trees = ['(S (PP-TMP (Cs-H Sau) (NP (Nt-H khi) (SBAR (Cs *0*) (S (NP-SBJ (NONE *-1)) (VP (Nn-H thoả_thuận) (NP (Nn-H giá_cả) (NP (Num 10.000) (Nu-H đồng_[]_Nu-H kg)))))))) (PU ,) (NP-SBJ (Nn-H công_việc) (Ve còn_lại) (PP (Cs-H của) (NP-1 (Nn-H anh_em) (Nr Bùi_A)))) (VP (Vc-H là) (VP-CMP (Vv-H bắt) (NP (Nn-H chó)) (VP (D-H vào) (NP (Nn-H rọ))))) (PU .))']\n",
        "  with open(f'/content/OneLine/{folder}/[Line]{filename}','r',encoding='utf8') as reader:\n",
        "    lines = reader.readlines()\n",
        "  dependency_tree_list = []\n",
        "  for line in lines:\n",
        "    #print(filename, line)\n",
        "    dependency_tree = []\n",
        "    tree = Tree.fromstring(line)\n",
        "    original_tree = Tree.fromstring(line)\n",
        "    relations = get_all_relation(tree)\n",
        "    POS_tags = get_all_POS(tree)\n",
        "    function_tag_list = get_function_tag(tree)\n",
        "    for index, word in enumerate(original_tree.leaves()):\n",
        "      word_index = str(index+1)\n",
        "      head_index = relations[word_index][0]\n",
        "      relation = relations[word_index][1]\n",
        "      POS = POS_tags[index]\n",
        "      function_tag = function_tag_list[word_index]\n",
        "      dependency_tree.append([word_index, word, '_', POS, '_', function_tag, head_index, relation,'_','_'])\n",
        "    dependency_tree_list.append(dependency_tree)\n",
        "  return dependency_tree_list"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mp0RSgUiuIg"
      },
      "source": [
        "## Thêm second relation\n",
        "+ Nguyên nhân: một số nhãn NULL có index refer tới các phrase nên khi khử nhãn NULL -> sửa các relaiton mà chỉ đến  NULL sang chỉ đến phrase mà NULL đề cập tới nhưng làm vậy là sai vì một phrase chỉ được phép nhận 1 head nên việc sửa này được coi là 1 đặc trưng phụ(second relation)\n",
        "+ Các bước: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcw5zPY5i0CA"
      },
      "source": [
        "# Lấy các label có index\n",
        "def get_phrase_contain_index(tree):\n",
        "  phrase_index_list = []\n",
        "  phrase_address_list = get_all_subtree_address(tree)\n",
        "  for phrase_address in phrase_address_list:\n",
        "    subtree_label = get_subtree(phrase_address, tree).label()\n",
        "    if re.search('[0-9]$', subtree_label):\n",
        "      phrase_type = subtree_label.split('-')[0]\n",
        "      index = subtree_label.split('-')[-1]\n",
        "      phrase_index = phrase_type + '-' + index\n",
        "      phrase_index_list.append((phrase_address, phrase_index))\n",
        "\n",
        "  phrase_index_dic = dict()\n",
        "  #Thêm ràng buộc\n",
        "  #if phrase_index_list:\n",
        "  for phrase_index, phrase_address in groupby(sorted(phrase_index_list, key = lambda ele: ele[1]), key = lambda ele: ele[1]):\n",
        "    phrase_index_dic[phrase_index] = [ele[0] for ele in phrase_address]\n",
        "  return phrase_index_dic"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgJ4aZmQi4Ly"
      },
      "source": [
        "# Lấy các vị trí của NULL-word trong câu\n",
        "def get_phrase_has_linked_NULL(tree):\n",
        "  word_list = tree.leaves()\n",
        "  tree = from_word_to_number(tree)\n",
        "  result = []\n",
        "  for word, leafPos in zip(word_list, tree.treepositions('leaves')):\n",
        "    if re.search('^\\*', word) and word[-1].isnumeric():\n",
        "      i = -1\n",
        "      index_word = tree[leafPos]\n",
        "      address = leafPos[:i]\n",
        "      POS = tree[address].label()\n",
        "      while (POS == 'NONE') or (not POS.isupper()):\n",
        "        i = i - 1\n",
        "        address = leafPos[:i]\n",
        "        POS = tree[address].label()\n",
        "      phrase_type = POS.split('-')[0]\n",
        "      NULL_index = word[-1]\n",
        "      phrase_index = phrase_type + '-' + NULL_index\n",
        "      result.append([index_word, phrase_index, list(address)])\n",
        "  return result"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3BSOMZpi7y1"
      },
      "source": [
        "# Trong trường hợp tìm mapping phrase cho NULLword mà có nhiều mapping phrase\n",
        "# Tính khoảng cách xem NULLword gần với mapping phrase nào nhất?\n",
        "def get_distance(phrase_address, map_address):\n",
        "  count = 0\n",
        "  for phrase_address_index, map_address_index in zip(phrase_address, map_address):\n",
        "    if phrase_address_index - map_address_index == 0:\n",
        "      count = count + 1\n",
        "    else:\n",
        "      return count\n",
        "  return count"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnDcRTKCi_F5"
      },
      "source": [
        "def find_map_phrase_address(phrase_of_NULL, map_phrase_list):\n",
        "# Ưu tiên 1\n",
        "  phrase_index = phrase_of_NULL[1]\n",
        "  phrase_address = phrase_of_NULL[2]\n",
        "  for map_phrase, map_phrase_address in map_phrase_list.items():\n",
        "    if map_phrase == phrase_index:\n",
        "      if len(map_phrase_address) >=2:\n",
        "        distance = []\n",
        "        for address in map_phrase_address:\n",
        "          distance.append(get_distance(phrase_address, address))\n",
        "        selected_index = distance.index(max(distance))\n",
        "        return map_phrase_address[selected_index]\n",
        "      else:\n",
        "        return map_phrase_address[0]\n",
        "\n",
        "# Ưu tiên 2 \n",
        "  map_phrase_exception = {\n",
        "      'NP':'^(Nc|Ncs|Nu|Nun|Nt|Nq|Num|Nw|Nr|Nn)',\n",
        "      'VP':'^(Ve|Vc|D|Vcp|Vv)',\n",
        "      'ADJP':'^(An|Aa)',\n",
        "      'S':'^SQ',\n",
        "      'SQ':'^S($)'\n",
        "  }\n",
        "  for map_phrase, map_phrase_address in map_phrase_list.items():\n",
        "    #print(phrase_index)\n",
        "    phrase_type = phrase_index.split('-')[0]\n",
        "    index_of_phrase = phrase_index.split('-')[1]\n",
        "    if phrase_type in map_phrase_exception:\n",
        "      if re.search(map_phrase_exception[phrase_type], map_phrase) and map_phrase[-1] == index_of_phrase:\n",
        "        if len(map_phrase_address) >=2:\n",
        "          distance = []\n",
        "          for address in map_phrase_address:\n",
        "            distance.append(get_distance(phrase_address, address))\n",
        "          selected_index = distance.index(max(distance))\n",
        "          return map_phrase_address[selected_index]\n",
        "        else:\n",
        "          return map_phrase_address[0]\n",
        "  return False"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k-r7ut2jAeg"
      },
      "source": [
        "def add_second_relation(tree, dependency_tree, linked_NULL_list, map_phrase_list):\n",
        "  #if linked_NULL_list and map_phrase_list:\n",
        "  headword_of_phrase = assign_headword_for_phrase(tree)[0]\n",
        "  for linked_NULL in linked_NULL_list:\n",
        "    element = dependency_tree[int(linked_NULL[0])-1]\n",
        "    head_index = element[6]\n",
        "    relation = element[7]\n",
        "    map_phrase_address = find_map_phrase_address(linked_NULL, map_phrase_list)\n",
        "    if map_phrase_address != False:\n",
        "      map_index = headword_of_phrase[str(map_phrase_address)]\n",
        "      map_element = dependency_tree[int(map_index)-1]\n",
        "      second_dep = map_element[8]\n",
        "      if second_dep == '_':\n",
        "        map_element[8] = head_index + ':' + relation\n",
        "      else:\n",
        "        map_element[8] = map_element[8] + '|' + head_index + ':' + relation\n",
        "  return dependency_tree"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcPqM3JD9zGX"
      },
      "source": [
        "tree = Tree.fromstring('(S (S (NP-SBJ (NONE *-1)) (VP-MNR (Vv-H Thấy) (SBAR-CMP (Cs *0*) (S (NP-SBJ (Pp-H chúng_tôi)) (VP (Vv-H thất_vọng) (VP (Vv-H quay) (R ra))))))) (PU ,) (NP-SBJ-1 (NP (Nn-H chị) (PU \") (Nn dịch_vụ) (PU \") (VP (Vv-H mời) (NP-DOB-1 (Pp-H chúng_tôi)) (PP (Cs-H vào) (NP (Cs trong))) (NP-TMP (Nt-H lúc) (SBAR (Cs *0*) (S (NP-SBJ (NONE *-1)) (VP (R mới) (Vv-H đến))))))) (Cp và) (NP (Nn_swsp (Nc-H ông) (Nn thường_trực)))) (VP (Cp vừa) (Vv-H nói) (Cp vừa) (Vv-H cười) (SBAR-CMP (Cs *0*) (PU :) (PU \") (S (NP-SBJ (NONE *E*)) (VP (VP (Vv-H Thấy) (R chưa)) (PU ,) (VP (Ve-H mất) (NP-CMP (M có) (Num 10) (Nun-H đôla) (PP (Cs-H cho) (NP (Pp-H chúng_tôi))))) (Cp thì) (VP (R có_khi) (NP-TMP (Pd-H bây_giờ)) (VP (R đã) (VA-H xong) (R rồi))) (PU ,) (VP (Vv-H thích) (VP (Vv-H làm) (ADJP (Aa-H thẳng)))) (Cp thì) (VP (Vv-H chờ) (PP-TMP (Cs-H đến) (NP (Nt-H chiều) (Aa muộn))) (M nhé)))) (PU \"))) (PU .))')\n",
        "original_tree = Tree.fromstring('(S (S (NP-SBJ (NONE *-1)) (VP-MNR (Vv-H Thấy) (SBAR-CMP (Cs *0*) (S (NP-SBJ (Pp-H chúng_tôi)) (VP (Vv-H thất_vọng) (VP (Vv-H quay) (R ra))))))) (PU ,) (NP-SBJ-1 (NP (Nn-H chị) (PU \") (Nn dịch_vụ) (PU \") (VP (Vv-H mời) (NP-DOB-1 (Pp-H chúng_tôi)) (PP (Cs-H vào) (NP (Cs trong))) (NP-TMP (Nt-H lúc) (SBAR (Cs *0*) (S (NP-SBJ (NONE *-1)) (VP (R mới) (Vv-H đến))))))) (Cp và) (NP (Nn_swsp (Nc-H ông) (Nn thường_trực)))) (VP (Cp vừa) (Vv-H nói) (Cp vừa) (Vv-H cười) (SBAR-CMP (Cs *0*) (PU :) (PU \") (S (NP-SBJ (NONE *E*)) (VP (VP (Vv-H Thấy) (R chưa)) (PU ,) (VP (Ve-H mất) (NP-CMP (M có) (Num 10) (Nun-H đôla) (PP (Cs-H cho) (NP (Pp-H chúng_tôi))))) (Cp thì) (VP (R có_khi) (NP-TMP (Pd-H bây_giờ)) (VP (R đã) (VA-H xong) (R rồi))) (PU ,) (VP (Vv-H thích) (VP (Vv-H làm) (ADJP (Aa-H thẳng)))) (Cp thì) (VP (Vv-H chờ) (PP-TMP (Cs-H đến) (NP (Nt-H chiều) (Aa muộn))) (M nhé)))) (PU \"))) (PU .))')\n",
        "dup_tree = Tree.fromstring('(S (S (NP-SBJ (NONE *-1)) (VP-MNR (Vv-H Thấy) (SBAR-CMP (Cs *0*) (S (NP-SBJ (Pp-H chúng_tôi)) (VP (Vv-H thất_vọng) (VP (Vv-H quay) (R ra))))))) (PU ,) (NP-SBJ-1 (NP (Nn-H chị) (PU \") (Nn dịch_vụ) (PU \") (VP (Vv-H mời) (NP-DOB-1 (Pp-H chúng_tôi)) (PP (Cs-H vào) (NP (Cs trong))) (NP-TMP (Nt-H lúc) (SBAR (Cs *0*) (S (NP-SBJ (NONE *-1)) (VP (R mới) (Vv-H đến))))))) (Cp và) (NP (Nn_swsp (Nc-H ông) (Nn thường_trực)))) (VP (Cp vừa) (Vv-H nói) (Cp vừa) (Vv-H cười) (SBAR-CMP (Cs *0*) (PU :) (PU \") (S (NP-SBJ (NONE *E*)) (VP (VP (Vv-H Thấy) (R chưa)) (PU ,) (VP (Ve-H mất) (NP-CMP (M có) (Num 10) (Nun-H đôla) (PP (Cs-H cho) (NP (Pp-H chúng_tôi))))) (Cp thì) (VP (R có_khi) (NP-TMP (Pd-H bây_giờ)) (VP (R đã) (VA-H xong) (R rồi))) (PU ,) (VP (Vv-H thích) (VP (Vv-H làm) (ADJP (Aa-H thẳng)))) (Cp thì) (VP (Vv-H chờ) (PP-TMP (Cs-H đến) (NP (Nt-H chiều) (Aa muộn))) (M nhé)))) (PU \"))) (PU .))')\n",
        "relations = get_all_relation(tree)\n",
        "POS_tags = get_all_POS(tree)\n",
        "function_tag_list = get_function_tag(tree)\n",
        "dependency_tree = []\n",
        "for index, word in enumerate(original_tree.leaves()):\n",
        "  word_index = str(index+1)\n",
        "  head_index = relations[word_index][0]\n",
        "  relation = relations[word_index][1]\n",
        "  POS = POS_tags[index]\n",
        "  function_tag = function_tag_list[word_index]\n",
        "  dependency_tree.append([word_index, word, '_', POS, '_', function_tag, head_index, relation,'_','_'])\n",
        "\n",
        "linked_NULL_list = get_phrase_has_linked_NULL(dup_tree)\n",
        "map_phrase_list = get_phrase_contain_index(dup_tree)\n",
        "new_dependency_tree = add_second_relation(dup_tree, dependency_tree, linked_NULL_list, map_phrase_list)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGXYOUTTmJFQ"
      },
      "source": [
        "# Đưa second_relation của NULL lên map phrase\n",
        "def edit_second_relation_of_NULL(tree, dependency_tree, linked_NULL_list, map_phrase_list):\n",
        "  headword_of_phrase = assign_headword_for_phrase(tree)[0]\n",
        "  for linked_NULL in linked_NULL_list:\n",
        "    element = dependency_tree[int(linked_NULL[0])-1]\n",
        "    head_index = element[6]\n",
        "    second_relation = element[8]\n",
        "    if second_relation != '_':\n",
        "      map_phrase_address = find_map_phrase_address(linked_NULL, map_phrase_list)\n",
        "      if map_phrase_address != False:\n",
        "        map_index = headword_of_phrase[str(map_phrase_address)]\n",
        "        map_element = dependency_tree[int(map_index)-1]\n",
        "        second_dep = map_element[8]\n",
        "        if second_dep == '_':\n",
        "          map_element[8] = second_relation\n",
        "        else:\n",
        "          map_element[8] = map_element[8] + '|' + second_relation\n",
        "  return dependency_tree"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEMeG1szmfYY"
      },
      "source": [
        "## Relink headNULL\n",
        "+ Nguyên nhân: do khi áp dụng luật chuyển đổi vô tình lấy nhãn NULL làm head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21Sj8NdEmWPo"
      },
      "source": [
        "# Lấy các mối quan hệ mà NULL làm head\n",
        "def get_dep_dic_of_NULL(dependency_tree):\n",
        "  dep_dic = {}\n",
        "  for element in dependency_tree:\n",
        "    word_index = element[0]\n",
        "    word = element[1]\n",
        "    NULL_pos = element[3]\n",
        "    NULL_head_index = element[6]\n",
        "    NULL_relation = element[7]\n",
        "    if re.search('^\\*', word):\n",
        "      dep_index_list = []\n",
        "      pos_list = []\n",
        "      word_list = []\n",
        "      for temp in dependency_tree:\n",
        "        dep_word_index = temp[0]\n",
        "        dep_word = temp[1]\n",
        "        pos_of_dep_word = temp[3]\n",
        "        head_index = temp[6]\n",
        "        if head_index == word_index :\n",
        "          dep_index_list.append(dep_word_index)\n",
        "          pos_list.append(pos_of_dep_word)\n",
        "          word_list.append(dep_word)\n",
        "      if dep_index_list:\n",
        "        dep_dic[word_index] = [NULL_pos, NULL_head_index, NULL_relation, dep_index_list, pos_list, word_list]\n",
        "  return dep_dic"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rO30RXZmXp_"
      },
      "source": [
        "# Chọn một từ mà có mối quan hệ với NULL và trong đó NULL làm head\n",
        "# Từ được chọn sẽ thay thế NULL làm head cho các mối quan hệ liên quan tới NULL\n",
        "def select_index(NULL_pos, dep_index_list, pos_list, word_list):\n",
        "  phrase_type_list = ['^(NP|Nc|Ncs|Nu|Nun|Nt|Nq|Num|Nw|Nr|Nn)', '^(VP|Ve|Vc|D|Vcp|Vv)', '^(ADJP|An|Aa)']\n",
        "  for phrase_type in phrase_type_list:\n",
        "    if re.search(phrase_type, NULL_pos):\n",
        "      for dep_index, pos, word in zip(dep_index_list, pos_list, word_list):\n",
        "        if (re.search(phrase_type, pos)) and ('*' not in word):\n",
        "          return dep_index\n",
        "  for dep_index, pos, word in zip(dep_index_list, pos_list, word_list):\n",
        "    if (pos != 'PU') and (pos != 'Cp') and (pos != 'Cs') and ('*' not in word):\n",
        "      return dep_index\n",
        "\n",
        "  for dep_index, pos, word in zip(dep_index_list, pos_list, word_list):\n",
        "    if (pos != 'PU') and ('*' not in word):\n",
        "      return dep_index"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm15sn_AmZgf"
      },
      "source": [
        "def relink_head_NULL(dependency_tree):\n",
        "  head_NULL_dic = get_dep_dic_of_NULL(dependency_tree)\n",
        "  if head_NULL_dic:\n",
        "    for NULL_index, dep_list in head_NULL_dic.items():\n",
        "      NULL_pos = dep_list[0]\n",
        "      NULL_head_index = dep_list[1]\n",
        "      NULL_relation = dep_list[2]\n",
        "      dep_index_list = dep_list[3]\n",
        "      pos_list = dep_list[4]\n",
        "      word_list = dep_list[5]\n",
        "      if (len(word_list) == 1) and ('*' not in word_list[0]):\n",
        "        selected_index = dep_index_list[0]\n",
        "        selected_element = dependency_tree[int(selected_index)-1]\n",
        "        selected_element[6] = NULL_head_index\n",
        "        selected_element[7] = NULL_relation\n",
        "\n",
        "        for element in dependency_tree:\n",
        "          second_relation_field = element[8]\n",
        "          second_relation_list = second_relation_field.split('|')\n",
        "          second_relation_list = [ selected_index +':'+second_relation.split(':')[1] if second_relation.split(':')[0] == NULL_index else second_relation for second_relation in second_relation_list] \n",
        "          element[8] = '|'.join(second_relation_list)\n",
        "\n",
        "      elif len(word_list) >= 2:\n",
        "        selected_index = select_index(NULL_pos, dep_index_list, pos_list, word_list)\n",
        "        selected_element = dependency_tree[int(selected_index)-1]\n",
        "        selected_element[6] = NULL_head_index\n",
        "        selected_element[7] = NULL_relation\n",
        "\n",
        "        for element in dependency_tree:\n",
        "          head_index = element[6]\n",
        "          if head_index == NULL_index:\n",
        "            element[6] = selected_index\n",
        "\n",
        "          second_relation_field = element[8]\n",
        "          second_relation_list = second_relation_field.split('|')\n",
        "          second_relation_list = [ selected_index +':'+second_relation.split(':')[1] if second_relation.split(':')[0] == NULL_index else second_relation for second_relation in second_relation_list] \n",
        "          element[8] = '|'.join(second_relation_list)\n",
        "  return dependency_tree"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omNBgM6qnV8_"
      },
      "source": [
        "##Khử nhãn NULL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm9lwnBenn8g"
      },
      "source": [
        "def minus_1(start_index, end_index):\n",
        "  minus_1 = {}\n",
        "  for index in range(start_index, end_index+1):\n",
        "    minus_1[str(index)]=str(index-1)\n",
        "  return minus_1 "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VfwPGEan2Sw"
      },
      "source": [
        "def map_index(tree_dependency, minus_1):\n",
        "\n",
        "  for relation in tree_dependency:\n",
        "    word_index = relation[0]\n",
        "    if word_index in minus_1:\n",
        "      relation[0] = minus_1[word_index]\n",
        "\n",
        "    head_index = relation[6]\n",
        "    if head_index in minus_1:\n",
        "      relation[6] = minus_1[head_index]\n",
        "\n",
        "    if relation[8] != '_':\n",
        "      new_second_dependency = []\n",
        "      second_dependency_element = relation[8]\n",
        "      second_dependency_list = second_dependency_element.split('|')\n",
        "      for second_dependency in second_dependency_list:\n",
        "        split_second_dependency = second_dependency.split(':')\n",
        "        number = split_second_dependency[0]\n",
        "        dep = split_second_dependency[1]\n",
        "        if number in minus_1:\n",
        "          second_dependency = minus_1[number] +':'+ dep\n",
        "        new_second_dependency.append(second_dependency)\n",
        "      relation[8] = '|'.join(new_second_dependency)\n",
        "\n",
        "  return tree_dependency\n",
        "    "
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOQuD4DMn4Bn"
      },
      "source": [
        "def remove_NULL(tree_dependency):\n",
        "  #Xóa các second relation mà có head_index trong với head_index chính thức và index_word\n",
        "  for index, element in enumerate(tree_dependency):\n",
        "      index_word = index+1\n",
        "      head_index = element[6]\n",
        "      second_relation_field = element[8]\n",
        "      if second_relation_field != '_':\n",
        "        new_second_relation_list = []\n",
        "        second_relation_list = second_relation_field.split('|')\n",
        "        for second_relation in second_relation_list:\n",
        "          s_head_index = second_relation.split(':')[0]\n",
        "          if (s_head_index != str(index_word)) and (s_head_index != head_index):\n",
        "            new_second_relation_list.append(second_relation)\n",
        "        if new_second_relation_list:\n",
        "          element[8] = '|'.join(new_second_relation_list)\n",
        "        else:\n",
        "          element[8] = '_'\n",
        "\n",
        "  #Khử nhãn NULL\n",
        "  check_null_1 = True\n",
        "  while check_null_1:\n",
        "    for index, element in enumerate(tree_dependency):\n",
        "      check_null_2 = True\n",
        "      word = element[1]\n",
        "      index_word = index+1\n",
        "\n",
        "      if re.search('(^\\*)', word):\n",
        "        minus = minus_1(index_word+1, len(tree_dependency))\n",
        "        tree_dependency = map_index(tree_dependency, minus)\n",
        "        del tree_dependency[index]\n",
        "        check_null_2 = False\n",
        "        break\n",
        "    if check_null_2:\n",
        "      check_null_1 = False\n",
        "  return tree_dependency"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhPNziFXoiQx"
      },
      "source": [
        "# Tạo file CONLLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGuV9x0Cok8o"
      },
      "source": [
        "def finish_dependency_tree(folder, filename, dependency_treebank):\n",
        "  with open(f'/content/OneLine/{folder}/[Line]{filename}','r',encoding='utf8') as reader:\n",
        "    lines = reader.readlines()\n",
        "  new_filename = filename[:-4] + '.conllu'\n",
        "  with open(f'/content/VnDep/{folder}/[VnDep]{new_filename}','w',encoding='utf8') as writer:\n",
        "    tree_index = 1 \n",
        "    for line, dependency_tree in zip(lines, dependency_treebank):\n",
        "      print(filename,line)\n",
        "      tree = Tree.fromstring(line)\n",
        "      linked_NULL_list = get_phrase_has_linked_NULL(tree)\n",
        "      map_phrase_list = get_phrase_contain_index(tree)\n",
        "\n",
        "      new_dependency_tree = add_second_relation(tree, dependency_tree, linked_NULL_list, map_phrase_list)\n",
        "      edit_dependency_tree = edit_second_relation_of_NULL(tree, new_dependency_tree, linked_NULL_list, map_phrase_list)\n",
        "      relink_headNULL_dependency_tree = relink_head_NULL(edit_dependency_tree)\n",
        "      remove_NULL_dependency_tree = remove_NULL(relink_headNULL_dependency_tree)\n",
        "      \n",
        "      writer.write('# ID = {}\\n'.format(tree_index))\n",
        "      tree_index = tree_index + 1\n",
        "      for element in edit_dependency_tree:\n",
        "        writer.write('\\t'.join(element))\n",
        "        writer.write('\\n')\n",
        "      writer.write('\\n')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpKPrdbsdyyW"
      },
      "source": [
        "##Kiểm tra lại cây sau khi khử NULL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKaHSaNXfAjL"
      },
      "source": [
        "def get_second_head_index(second_relation_field):\n",
        "  if second_relation_field != '_':\n",
        "    second_relation_list = second_relation_field.split('|')\n",
        "    return [second_relation.split(':')[0] for second_relation in second_relation_list]\n",
        "  else:\n",
        "    return False"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUMiV46Ch13b"
      },
      "source": [
        "def print_dependency_tree(dependency_tree):\n",
        "  for ele in dependency_tree:\n",
        "    print(ele)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxZo-TTPdIA0"
      },
      "source": [
        "def check_dependency_tree(folder, filename, dependency_treebank):\n",
        "  with open(f'/content/OneLine/{folder}/[Line]{filename}','r',encoding='utf8') as reader:\n",
        "    lines = reader.readlines() \n",
        "    for line, dependency_tree in zip(lines, dependency_treebank):\n",
        "      \n",
        "      tree = Tree.fromstring(line)\n",
        "      linked_NULL_list = get_phrase_has_linked_NULL(tree)\n",
        "      map_phrase_list = get_phrase_contain_index(tree)\n",
        "\n",
        "      new_dependency_tree = add_second_relation(tree, dependency_tree, linked_NULL_list, map_phrase_list)\n",
        "      edit_dependency_tree = edit_second_relation_of_NULL(tree, new_dependency_tree, linked_NULL_list, map_phrase_list)\n",
        "      relink_headNULL_dependency_tree = relink_head_NULL(edit_dependency_tree)\n",
        "      before_remove_NULL = copy.copy(relink_headNULL_dependency_tree)\n",
        "      remove_NULL_dependency_tree = remove_NULL(relink_headNULL_dependency_tree)\n",
        "\n",
        "      #Check sau khi khử NULL\n",
        "      index_word_list = []\n",
        "      head_index_list = []\n",
        "      second_head_index_list = []\n",
        "      for element in remove_NULL_dependency_tree:\n",
        "        index_word_list.append(element[0])\n",
        "        if element[6] != '0':\n",
        "          head_index_list.append(element[6])\n",
        "        if get_second_head_index(element[8]):\n",
        "          second_head_index_list.append(get_second_head_index(element[8]))\n",
        "\n",
        "      for head_index in head_index_list:\n",
        "        if head_index not in index_word_list:\n",
        "          print(filename, line)\n",
        "          print('head_index', head_index)\n",
        "          print_dependency_tree(before_remove_NULL)\n",
        "\n",
        "      for second_head_index in second_head_index_list:\n",
        "        for index in second_head_index:\n",
        "          if index not in index_word_list: \n",
        "            print(filename, line)\n",
        "            print('second_index', index)\n",
        "            print_dependency_tree(before_remove_NULL)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3Yl_k24o1L4"
      },
      "source": [
        "# from google.colab import files\n",
        "# file_list = ['Dev_4784','Dev_25432','Dev_25480','Dev_25600','Dev_26554','Dev_46137','Dev_7105','Dev_7276','Dev_81347','Dev_90295','Dev_9539']\n",
        "# dependency_treebank_list = []\n",
        "# for file in file_list:\n",
        "#   to_oneline(file)\n",
        "#   dependency_treebank = get_dependency_tree_list(file)\n",
        "#   finish_dependency_tree(file, dependency_treebank)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aifXvng3dVCX"
      },
      "source": [
        "#Thực hiện trên toàn NIIVTB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBntWVbsdaE8"
      },
      "source": [
        "!cp /content/drive/MyDrive/NIIVTB/NIIVTB-1.zip /content"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtwK3lr8rLf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666c7623-13d4-44ea-f302-186a055b65d4"
      },
      "source": [
        "!unzip /content/NIIVTB-1.zip"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/NIIVTB-1.zip\n",
            "   creating: NIIVTB-1/\n",
            "   creating: NIIVTB-1/Dev/\n",
            "  inflating: NIIVTB-1/Dev/Dev_25283.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25283.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25300.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25300.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25302.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25302.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25432.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25432.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25433.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25433.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25435.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25435.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25480.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25480.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25600.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_25600.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_26554.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_26554.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_46137.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_46137.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_4784.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_4784.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_5770.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_5770.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_59422.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_59422.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_6046.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_6046.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_7105.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_7105.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_7276.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_7276.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_80432.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_80432.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_81003.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_81003.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_81347.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_81347.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_82172.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_82172.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_82515.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_82515.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_90189.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_90189.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_90295.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_90295.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_90723.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_90723.raw  \n",
            "  inflating: NIIVTB-1/Dev/Dev_9539.prd  \n",
            "  inflating: NIIVTB-1/Dev/Dev_9539.raw  \n",
            "   creating: NIIVTB-1/Test/\n",
            "  inflating: NIIVTB-1/Test/Test_25272.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_25272.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_25288.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_25288.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_25303.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_25303.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_25311.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_25311.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_25344.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_25344.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_25460.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_25460.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_25463.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_25463.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_25464.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_25464.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_25472.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_25472.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_25475.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_25475.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_25849.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_25849.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_45208.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_45208.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_46019.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_46019.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_46273.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_46273.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_50056.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_50056.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_5498.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_5498.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_5642.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_5642.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_59792.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_59792.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_7850.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_7850.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_79859.test.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_79859.test.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_80049.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_80049.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_80610.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_80610.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_81911.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_81911.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_82039.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_82039.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_8322.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_8322.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_8456.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_8456.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_90483.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_90483.raw  \n",
            "  inflating: NIIVTB-1/Test/Test_90854.prd  \n",
            "  inflating: NIIVTB-1/Test/Test_90854.raw  \n",
            "   creating: NIIVTB-1/Train/\n",
            "  inflating: NIIVTB-1/Train/Train_109898.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_109898.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_25439.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_25439.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_254761.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_254761.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_25627.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_25627.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_26558.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_26558.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_26749.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_26749.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_28472.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_28472.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45096.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45096.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45098.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45098.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45189.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45189.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45205.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45205.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45329.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45329.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45425.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45425.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45428.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45428.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45436.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45436.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45562.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45562.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45658.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45658.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45676.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45676.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45732.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45732.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45791.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45791.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45817.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45817.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45903.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45903.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_45930.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_45930.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46027.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46027.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46052.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46052.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46165.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46165.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46245.test.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46245.test.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46367.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46367.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46485.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46485.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46489.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46489.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46546.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46546.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46549.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46549.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46685.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46685.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46692.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46692.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46710.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46710.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46762.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46762.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46779.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46779.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46803.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46803.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46851.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46851.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_46965.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_46965.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_4899.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_4899.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_49.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_49.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_50096.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_50096.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_50232.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_50232.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_50252.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_50252.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_50362.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_50362.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_50501.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_50501.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_51004.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_51004.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_51007.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_51007.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_51010.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_51010.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_51012.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_51012.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_51392.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_51392.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_51496.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_51496.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_58479.test.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_58479.test.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_58561.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_58561.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_58799.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_58799.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_58948.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_58948.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_58952.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_58952.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_59085.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_59085.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_59098.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_59098.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_59127.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_59127.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_59169.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_59169.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_59256.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_59256.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_5932.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_5932.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_59401.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_59401.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_59602.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_59602.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_59605.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_59605.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_59770.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_59770.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_59910.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_59910.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_59933.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_59933.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_60050.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_60050.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_60083.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_60083.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_60200.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_60200.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_60233.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_60233.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_60296.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_60296.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_60358.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_60358.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_60681.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_60681.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_6207.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_6207.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_6386.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_6386.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_6825.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_6825.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_6972.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_6972.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_7398.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_7398.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_7606.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_7606.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_7818.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_7818.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_80010.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_80010.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_8010.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_8010.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_80192.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_80192.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_80237.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_80237.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_80244.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_80244.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_80436.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_80436.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_80628.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_80628.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_80757.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_80757.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_80865.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_80865.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_80993.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_80993.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_81161.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_81161.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_81173.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_81173.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_81344.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_81344.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_81531.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_81531.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_81533.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_81533.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_8160.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_8160.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_81719.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_81719.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_81724.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_81724.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_81914.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_81914.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_82156.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_82156.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_8626.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_8626.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_8784.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_8784.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_8927.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_8927.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_90069.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_90069.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_90159.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_90159.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_90324.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_90324.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_90501.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_90501.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_90693.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_90693.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_90694.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_90694.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_90750.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_90750.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_90832.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_90832.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_9129.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_9129.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_92122.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_92122.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_92126.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_92126.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_92260.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_92260.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_9244.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_9244.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_9415.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_9415.raw  \n",
            "  inflating: NIIVTB-1/Train/Train_Mau.prd  \n",
            "  inflating: NIIVTB-1/Train/Train_Mau.raw  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-PgU7Pqs6qi"
      },
      "source": [
        "!mkdir /content/OneLine"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjqRT3olQ4hx"
      },
      "source": [
        "!mkdir /content/OneLine/Train \n",
        "!mkdir /content/OneLine/Dev \n",
        "!mkdir /content/OneLine/Test "
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJTWkDsZuV0s"
      },
      "source": [
        "!mkdir /content/VnDep"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpBDzqSjREJZ"
      },
      "source": [
        "!mkdir /content/VnDep/Train\n",
        "!mkdir /content/VnDep/Dev\n",
        "!mkdir /content/VnDep/Test"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNQF-j0ArQ_i"
      },
      "source": [
        "path_list = glob.glob('/content/NIIVTB-1/*/*.prd')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVAKZ4aerguB",
        "outputId": "3fac9b5a-edd0-4e3c-e14f-ebf225fbc127"
      },
      "source": [
        "for index, path in enumerate(path_list):\n",
        "  print(index+1)\n",
        "  folder = path.split('/')[-2]\n",
        "  filename = path.split('/')[-1]\n",
        "  to_oneline(folder, filename)\n",
        "  dependency_treebank = get_dependency_tree_list(folder, filename)\n",
        "  check_dependency_tree(folder, filename, dependency_treebank)\n",
        "  #print('{:.2f}'.format((index+1/len(path_list))*100))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PZPnf8syI_Y",
        "outputId": "93d0f522-f6bd-48e2-f34d-035c7720cd65"
      },
      "source": [
        "tree = Tree.fromstring('(S (PP-PRP (Cs-H Để) (VP (Vv-H làm) (R được) (PP (Cs-H như) (NP (Nn-H-1 mục_tiêu) (VP (Vv *P*) (VP-CMP (Vv-H đề) (R ra) (NP-DOB (Nn *D*-1)))))))) (PU ,) (S (NP-SBJ (NONE *-1)) (VP-ADV (ADJP (R không) (Aa-H phải)) (Vv-H đợi) (PP-TMP (Cs-H đến) (NP (Nt-H tháng) (VP (VA-H an_toàn) (NP (Nn-H giao_thông))) (NP-PRN (Nt-H tháng) (Num chín) (NP (R hằng) (Nt-H năm))))) (VP (R mới) (Vv-H hành_động)))) (Cp mà) (S (NP-SBJ (Nun-H TP)) (VP (Vv-H phải) (VP-CMP (Vv-H xem) (SBAR-CMP (Cs *0*) (S (NP-SBJ (NP (Nq mỗi) (Nu-H tháng)) (PU ,) (NP (Nq mỗi) (Nu-H ngày))) (VP (R-H đều) (Vc-H là) (PU \") (VP-CMP (VA-H an_toàn) (NP (Nn-H giao_thông))) (PU \"))))))) (PU .))')\n",
        "tree.pretty_print()\n",
        "(SQ (Cp Vì) (QNP-PRP (Pp-H sao)) (NP (Pp-H vậy))) (NP-VOC (M hở) (Nr-H Thuỳ)) (PU ?))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                                                          S                                                                                                                                            \n",
            "             _____________________________________________________________________________________________________________________________|__________________________________________________________________________________________________________________________________________   \n",
            "            |                                              |                                            |                                                                 |          S                                                                                               | \n",
            "            |                                              |                                            |                                                                 |     _____|_________                                                                                      |  \n",
            "          PP-PRP                                           |                                            |                                                                 |    |               VP                                                                                    | \n",
            "  __________|____________                                  |                                            |                                                                 |    |      _________|____________                                                                         |  \n",
            " |                       VP                                |                                            S                                                                 |    |     |                    VP-CMP                                                                     | \n",
            " |     __________________|______                           |     _______________________________________|____________                                                     |    |     |     _________________|______________________                                                  |  \n",
            " |    |     |                   PP                         |    |                                                  VP-ADV                                                 |    |     |    |                                     SBAR-CMP                                             | \n",
            " |    |     |      _____________|___                       |    |            ________________________________________|______________________________________              |    |     |    |     ___________________________________|______                                           |  \n",
            " |    |     |     |                 NP                     |    |           |         |                            PP-TMP                                   |             |    |     |    |    |                                          S                                          | \n",
            " |    |     |     |       __________|____                  |    |           |         |     _________________________|________                              |             |    |     |    |    |                    ______________________|________                                  |  \n",
            " |    |     |     |      |               VP                |    |           |         |    |                                  NP                            |             |    |     |    |    |                   |                               VP                                | \n",
            " |    |     |     |      |       ________|____             |    |           |         |    |      ____________________________|_____                        |             |    |     |    |    |                   |                       ________|_____________________________    |  \n",
            " |    |     |     |      |      |           VP-CMP         |    |           |         |    |     |            VP                  NP-PRN                    |             |    |     |    |    |                 NP-SBJ                   |   |    |          VP-CMP             |   | \n",
            " |    |     |     |      |      |    _________|______      |    |           |         |    |     |       _____|______          _____|__________             |             |    |     |    |    |        ___________|_________             |   |    |      ______|________        |   |  \n",
            " |    |     |     |      |      |   |         |    NP-DOB  |  NP-SBJ       ADJP       |    |     |      |            NP       |     |          NP           VP            |  NP-SBJ  |    |    |       NP          |         NP           |   |    |     |               NP      |   | \n",
            " |    |     |     |      |      |   |         |      |     |    |       ____|____     |    |     |      |            |        |     |      ____|___      ___|______       |    |     |    |    |    ___|____       |      ___|_____       |   |    |     |               |       |   |  \n",
            "Cs-H Vv-H   R    Cs-H  Nn-H-1   Vv Vv-H       R      Nn    PU  NONE    R        Aa-H Vv-H Cs-H  Nt-H   VA-H         Nn-H     Nt-H  Num    R       Nt-H  R         Vv-H    Cp Nun-H  Vv-H Vv-H  Cs  Nq      Nu-H    PU    Nq       Nu-H   R-H Vc-H  PU   VA-H            Nn-H     PU  PU\n",
            " |    |     |     |      |      |   |         |      |     |    |      |         |    |    |     |      |            |        |     |     |        |    |          |      |    |     |    |    |   |        |      |     |         |      |   |    |     |               |       |   |  \n",
            " Để  làm   được  như  mục_tiêu *P*  đề        ra   *D*-1   ,   *-1   không      phải đợi  đến  tháng an_toàn     giao_thông tháng  chín  hằng     năm  mới     hành_động  mà   TP   phải xem  *0* mỗi     tháng    ,    mỗi       ngày   đều  là   \"  an_toàn        giao_thông  \"   . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_QUCGv4QbEf",
        "outputId": "6a1e2c80-6107-4ce3-fd69-5ab3c8812098"
      },
      "source": [
        "!zip -r '/content/drive/MyDrive/NIIVTB/VnDependencyTreebank.zip' '/content/VnDep'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: /VnDep\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r /content/drive/MyDrive/NIIVTB/VnDependencyTreebank.zip . -i /VnDep)\n"
          ]
        }
      ]
    }
  ]
}