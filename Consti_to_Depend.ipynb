{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwhkuuTxdqlX"
   },
   "source": [
    "#1. Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JtC_E4WYcXOn"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pprint\n",
    "import copy\n",
    "from pprint import pprint\n",
    "from nltk.tree import Tree\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfCQm7U0d3Zg",
    "tags": []
   },
   "source": [
    "# 2. Các function thông dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aLYNuNqhd6sU"
   },
   "outputs": [],
   "source": [
    "# Dùng luật để kiểm tra label có phải là head hay không\n",
    "def is_head(rule, label):\n",
    "  return re.search(rule, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fqnJj7UteVKB"
   },
   "outputs": [],
   "source": [
    "# Vì lúc tìm headword cho các address(kiểu list) của các phrase\n",
    "# thì return về dic[address]=headword nhưng dic không lưu đc dạng list -> đổi list thành string\n",
    "# Nên khi sài lại address thì cần chuyển đổi list(kiểu string) thành real list\n",
    "def str_to_list(s):\n",
    "  result = []\n",
    "  num = ''\n",
    "  for i in s:\n",
    "    if i != '[' and i !=']':\n",
    "      if i != ',':\n",
    "        if i.isnumeric():\n",
    "          num +=i\n",
    "      else: \n",
    "        result.append(int(num))\n",
    "        num = ''\n",
    "  result.append(int(num))\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "n8l9byungXDu"
   },
   "outputs": [],
   "source": [
    "# Lấy tất cả index của các cây con \n",
    "def get_all_index_in_tree(tree):\n",
    "  result = []\n",
    "  for index, subtree in enumerate(tree):\n",
    "    if type(subtree) != str:\n",
    "      result.append([index])\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9BAo3bsogecm"
   },
   "outputs": [],
   "source": [
    "# Trả về cây con thông qua địa chỉ\n",
    "def get_subtree(subtree_address, tree):\n",
    "  if type(subtree_address) == str:\n",
    "    if subtree_address == 'root':\n",
    "      return tree\n",
    "    else:\n",
    "      subtree_address = str_to_list(subtree_address) \n",
    "  for index in subtree_address:\n",
    "    tree = tree[index]\n",
    "  return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sbAbYW9MgjBt"
   },
   "outputs": [],
   "source": [
    "#Khám phá tất cả các phrases.\n",
    "#Sử dụng thuật toán bfs - tìm kiếm theo chiều rộng\n",
    "def get_all_subtree_address(tree):\n",
    "  queue = get_all_index_in_tree(tree)\n",
    "  explored = []\n",
    "  while queue:\n",
    "    node = queue.pop(0)\n",
    "    if node not in explored:\n",
    "      explored.append(node)\n",
    "      subtree = get_subtree(node,tree)\n",
    "      index_subtree_list = get_all_index_in_tree(subtree)\n",
    "      for index_subtree in index_subtree_list:\n",
    "        queue.append(node+index_subtree)\n",
    "  return explored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dbWWMxcrgx5N"
   },
   "outputs": [],
   "source": [
    "#Do có thể xuất hiện nhiều từ giống nhau trong 1 câu\n",
    "#Nên sẽ khó xác định đâu là headword của phrase\n",
    "#-> Số hóa các từ trong câu: Mỗi từ sẽ biến đổi thành một số, số hóa bắt đầu từ số 1 \n",
    "def from_word_to_number(tree):\n",
    "  for index, leafPos in enumerate(tree.treepositions('leaves')):\n",
    "    tree[leafPos] = str(index+1)\n",
    "  return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "T4OZhzsBi5sF"
   },
   "outputs": [],
   "source": [
    "#Trong lúc đề xuất luật infer dependency label cần xét cả nhãn gốc của từ \n",
    "#Nhãn gốc là node gần nhất với node lá(từ)\n",
    "def get_POS_of_word(tree):\n",
    "  result = {}\n",
    "  for leafPos in tree.treepositions('leaves'):\n",
    "    word = tree[leafPos]\n",
    "    POS = tree[leafPos[:-1]].label()\n",
    "    result[word] = POS\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DopZTG4fjfe2"
   },
   "outputs": [],
   "source": [
    "#Trả về danh sách các nhãn gốc của từ, dùng để điền vào format CONLLU\n",
    "#Lưu ý: đối vs các nhãn NULL thì không lấy 'NONE' làm nhãn gốc\n",
    "#Vì NONE no-use trong việc relink khi NULL làm head ở phần hậu xử lý \n",
    "def get_all_POS(tree):\n",
    "  result = []\n",
    "  for leafPos in tree.treepositions('leaves'):\n",
    "    i = -1\n",
    "    POS = tree[leafPos[:i]].label().split('-')[0]\n",
    "    while POS == 'NONE':\n",
    "      i = i - 1\n",
    "      POS = tree[leafPos[:i]].label().split('-')[0]\n",
    "    result.append(POS)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MMRzJBa1ksL0"
   },
   "outputs": [],
   "source": [
    "#Follow theo Choi's guideline, lưu function_tag như đặc trưng phụ, được điền vào format CONLLU\n",
    "#Trả về function_tag của C(node cao nhất của headword)\n",
    "def get_function_tag(tree):\n",
    "  headword_of_phrase = assign_headword_for_phrase(tree)[0]\n",
    "  C_of_headword = get_C_of_headword(headword_of_phrase)\n",
    "  function_tags_of_word = {}\n",
    "  for word in tree.leaves():\n",
    "    C_label = get_subtree(C_of_headword[word], tree).label()\n",
    "    function_tags = C_label.split('-')\n",
    "    temp = []\n",
    "    for function_tag in function_tags:\n",
    "      if function_tag in ['PRD', 'CMP', 'LGS', 'CMP', 'MDP', 'TMP', 'LOC', 'MNR', 'PRP', 'ADV', 'CND', 'CNC']:\n",
    "        temp.append(function_tag)\n",
    "    if temp:\n",
    "      temp = '-'.join(temp)\n",
    "      function_tags_of_word[word] = temp\n",
    "    else:\n",
    "      function_tags_of_word[word] = '_'\n",
    "  return function_tags_of_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3ekdn2gln0Y"
   },
   "source": [
    "#3. Tìm headword cho các phrase\n",
    "**Các bước cụ thể:**\n",
    "\n",
    "+ Bước 1: Tìm head cho các phrase\n",
    "+ Bước 2: Loop bước 1 đi sâu xuống cây để xác định được headword\n",
    "\n",
    "**Lưu ý trong bước 1:**\n",
    "\n",
    "  Nếu số phần tử list head trả về > 1 thì xét:\n",
    "  + Nếu các label trong list head **giống nhau** thì thực hiện gán nhãn conjunction\n",
    "  + Nếu các label trong list head **khác nhau**:\n",
    "    + Xét trong khoảng từ first label đến last label trong list head có các nhãn như Cp, CONP, UCP thì gán nhãn conjunction.\n",
    "    + Nếu không phải trường hợp conjunction thì xét theo luật phụ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DtGXtiVal-Is"
   },
   "outputs": [],
   "source": [
    "# Trả về list các vị trí(index) có thể làm head và list label ứng với list các index \n",
    "def finding_head_of_tree(tree):\n",
    "#Một số thay đổi:\n",
    "#đổi VP, S ở S, và thêm PRD và VP, S ở SBAR thành VP, S, SBAr\n",
    "# THÊM sQ vào S ở S và SBAR\n",
    "# SQ: VP, Sq, S -> thêm VP và S\n",
    "# thêm SPL\n",
    "# Xem SPL như S ở S và SBAR\n",
    "# Đảo -PRD trc S|SQ|SPL của S\n",
    "# tÁCH VP thành 2 loại ở S\n",
    "  head_percolation_rules = {\n",
    "    \"S\":[\"-H$\",\"^VP(-CMP|_|$)\",\"-PRD$\",\"^VP-\",\"^(S|SQ|SPL)(-|_|$)\",\"^ADJP(-|_|$)\",\"^NP(-|_|$)\"],\n",
    "    \"SBAR\":[\"-H$\",\"^VP(-|_|$)\",\"^(S|SQ|SPL)(-|_|$)\",\"^SBAR(-|_|$)\",\"^ADJP(-|_|$)\",\"^NP(-|_|$)\"],\n",
    "    \"SQ\": [\"-H$\",\"^VP(-|_|$)\",\"^QVP(-|_|$)\",\"^SQ(-|_|$)\",\"^S(-|_|$)\",\"^ADJP(-|_|$)\",\"^NP(-|_|$)\", \"^QPP(-|_|$)\"],\n",
    "    \"NP\":[\"-H$\",\"^NP(-|_|$)\",\"^(Nc|Ncs|Nu|Nun|Nt|Nq|Num|Nw|Nr|Nn)(-|_|$)\",\"^(Pd|Pp)(-|_|$)\",\"^VP(-|_|$)\"],\n",
    "    \"VP\":[\"-H$\",\"^VP(-|_|$)\",\"^(Ve|Vc|D|Vcp|Vv)(-|_|$)\",\"^(An|Aa)(-|_|$)\",\"^ADJP(-|_|$)\",\"^(Nc|Ncs|Nu|Nun|Nt|Nq|Num|Nw|Nr|Nn)(-|_|$)\",\"^NP(-|_|$)\",\"^SBAR(-|_|$)\",\"^S(-|_|$)\",\"^R(-|_|$)\",\"^RP(-|_|$)\",\"^PP(-|_|$)\"],\n",
    "    \"ADJP\":[\"-H$\",\"^ADJP(-|_|$)\",\"^(An|Aa)(-|_|$)\",\"^(Nc|Ncs|Nu|Nun|Nt|Nq|Num|Nw|Nr|Nn)(-|_|$)\",\"^S(-|_|$)\"],\n",
    "    \"RP\":[\"-H$\",\"^RP(-|_|$)\",\"^R(-|_|$)\",\"^NP(-|_|$)\"],\n",
    "    \"PP\":[\"-H$\",\"^PP(-|_|$)\",\"^Cs(-|_|$)\",\"^VP(-|_|$)\",\"^SBAR(-|_|$)\",\"^ADJP(-|_|$)\",\"^QP(-|_|$)\"],\n",
    "    \"ADJP\":[\"-H$\",\"^ADJP(-|_|$)\",\"^A(-|_|$)\",\"^N(-|_|$)\",\"^S(-|_|$)\"],\n",
    "    \"QP\":[\"-H$\",\"^QP(-|_|$)\",\"^Nq(-|_|$)\",\"^Num(-|_|$)\",\"^Nw(-|_|$)\"],\n",
    "    \"XP\":[\"-H$\",\"^XP(-|_|$)\",\"^X(-|_|$)\"],\n",
    "    \"YP\":[\"-H$\",\"^YP(-|_|$)\",\"^Y(-|_|$)\"],\n",
    "    \"MDP\":[\"-H$\",\"^MDP(-|_|$)\", \"^E(-|_|$)\", \"^(An|Aa)(-|_|$)\",\"^(Pd|Pp)(-|_|$)\", \"^R(-|_|$)\", \"^X(-|_|$)\"],\n",
    "    \"QNP\":[\"-H$\",\"^QNP(-|_|$)\",\"^NP(-|_|$)\",\"^(Nc|Ncs|Nu|Nun|Nt|Nq|Num|Nw|Nr|Nn)(-|_|$)\",\"^(Pd|Pp)(-|_|$)\"],\n",
    "    \"QADJP\":[\"-H$\",\"^QADJP(-|_|$)\",\"^(An|Aa)(-|_|$)\",\"^(Nc|Ncs|Nu|Nun|Nt|Nq|Num|Nw|Nr|Nn)(-|_|$)\",\"^(Ve|Vc|D|Vcp|Vv)(-|_|$)\",\"^(Pd|Pp)(-|_|$)\",\"^X(-|_|$)\"],\n",
    "    \"QRP\":[\"-H$\",\"^QRP(-|_|$)\",\"^(Pd|Pp)(-|_|$)\",\"^Cs(-|_|$)\",\"^X(-|_|$)\"],\n",
    "    \"QPP\":[\"-H$\",\"^QPP(-|_|$)\",\"^Cs(-|_|$)\",\"^(Pd|Pp)(-|_|$)\",\"^X(-|_|$)\"],\n",
    "    \"QXP\":[\"-H$\",\"^XP(-|_|$)\",\"^X(-|_|$)\"],\n",
    "    \"QVP\":[\"-H$\",\"^(Ve|Vc|D|Vcp|Vv)(-|_|$)\"],\n",
    "    \"UCP\":[\"-H$\"],\n",
    "    \"SPL\":[\"-H$\",\"^VP(-|_|$)\",\"^SPL(-|_|$)\", \"^ADJP(-|_|$)\",\"^NP(-|_|$)\"]\n",
    "    }\n",
    "\n",
    "  phrase_type = tree.label().split('-')[0]\n",
    "\n",
    "  head_index_result = []\n",
    "  head_label_result = []\n",
    "  if  phrase_type not in head_percolation_rules:\n",
    "    for index, element in enumerate(tree):\n",
    "      label_of_element = element.label()\n",
    "      if is_head(\"-H$\", label_of_element):\n",
    "        head_index_result.append([index])\n",
    "        head_label_result.append(label_of_element)\n",
    "\n",
    "    if head_index_result:\n",
    "      return head_index_result, head_label_result\n",
    "    else:\n",
    "      return [[0]], [tree[0].label()] \n",
    "\n",
    "  if phrase_type == 'RP':\n",
    "    for rule in head_percolation_rules['RP']:\n",
    "      if not head_index_result:\n",
    "        for index, element in zip(range(len(tree)-1, -1, -1), reversed(tree)):\n",
    "          label_of_element = element.label()\n",
    "          if is_head(rule, label_of_element):\n",
    "            head_index_result.append([index])\n",
    "            head_label_result.append(label_of_element)\n",
    "      else: \n",
    "        break\n",
    "        \n",
    "    if head_index_result:\n",
    "      return head_index_result[::-1], head_label_result[::-1]\n",
    "    else: \n",
    "      return [[0]], [tree[0].label()] \n",
    "    \n",
    "  else:\n",
    "    for rule in head_percolation_rules[phrase_type]:\n",
    "      if not head_index_result:\n",
    "        for index, element in enumerate(tree):\n",
    "          label_of_element = element.label()\n",
    "          if is_head(rule, label_of_element):\n",
    "            head_index_result.append([index])\n",
    "            head_label_result.append(label_of_element)\n",
    "      else: \n",
    "        break\n",
    "        \n",
    "    if head_index_result:\n",
    "      return head_index_result, head_label_result\n",
    "    else: \n",
    "      return [[0]], [tree[0].label()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-EXuUj4kn2DL"
   },
   "outputs": [],
   "source": [
    "# Hàm dùng trong trường hợp các label trong head list khác nhau:\n",
    "# Hàm lấy các label trong khoảng từ first label -> last label trong head list \n",
    "# Để xét coi có Cp, UCP, CONJP\n",
    "def deepen_head_list(mother_tree, tree_address, head_index_list):\n",
    "  deep_address_list = []\n",
    "  deep_label_list = []\n",
    "  first_index = head_index_list[0][0]\n",
    "  last_index = head_index_list[-1][0]\n",
    "  for index in range(first_index, last_index+1):\n",
    "    if tree_address != 'root':\n",
    "      subtree_address = tree_address + [index]\n",
    "    else:\n",
    "      subtree_address = [index]\n",
    "    deep_address_list.append(subtree_address)\n",
    "    deep_label_list.append(get_subtree(subtree_address, mother_tree).label())\n",
    "  return deep_address_list, deep_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZHEICEJ8xELa"
   },
   "outputs": [],
   "source": [
    "# Dán nhãn conjunction \n",
    "def get_conjunction(P_address, C_address_list, C_label_list):\n",
    "  P_of_C_dic = {}\n",
    "  previous_C_address = str(C_address_list[0])\n",
    "  for C_address, C_label in zip(C_address_list[1:], C_label_list[1:]):\n",
    "    if C_label == 'PU':\n",
    "      P_of_C_dic[str(C_address)] = (previous_C_address, 'PUNCT')\n",
    "    elif re.search('^(Cp|CONJP)', C_label):\n",
    "      P_of_C_dic[str(C_address)] = (previous_C_address, 'CC')\n",
    "    else:\n",
    "      P_of_C_dic[str(C_address)] = (previous_C_address, 'CONJ')\n",
    "    if (C_label != 'PU') and (C_label != 'Cp') and ('CONJP' not in C_label):\n",
    "      previous_C_address = str(C_address)\n",
    "  return P_of_C_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "F52Tn7CIxHv5"
   },
   "outputs": [],
   "source": [
    "# Kiểm tra có phải là trường hợp conj hay không\n",
    "def is_conjunction(C_label_list):\n",
    "\n",
    "  unique = set(C_label_list)\n",
    "  if len(unique) == 3:\n",
    "    if ('PU' in unique) and ((('Cp' in unique) or ('CONJP' in unique)) and (('Cp' != C_label_list[0]) or ('CONJP' != C_label_list[0]))):\n",
    "      return True\n",
    "    elif (('PU' in unique) or ('Cp' in unique) or ('CONJP' in unique)) and ('SPL' in unique) and ('S' in unique):\n",
    "      return True\n",
    "  elif len(unique) == 2:\n",
    "    if ('PU' in unique) or ((('Cp' in unique) or ('CONJP' in unique)) and (('Cp' != C_label_list[0]) or ('CONJP' != C_label_list[0]))):\n",
    "      return True\n",
    "    elif ('SPL' in unique) and ('S' in unique):\n",
    "      return True\n",
    "  elif len(unique) == 1:\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "def has_same_phrase_type(C_label_list):\n",
    "  phrase_type_set= set()\n",
    "  for C_label in C_label_list:\n",
    "    phrase_type = C_label.split('-')[0]\n",
    "    phrase_type_set.add(phrase_type)\n",
    "    if len(phrase_type_set) == 2:\n",
    "      return False\n",
    "  return True\n",
    "\n",
    "#Dùng xác định head khi head list > 1\n",
    "def identify_head(tree, P_address, C_address_list, C_label_list, head_C_address_list, head_C_label_list):\n",
    "\n",
    "  if is_conjunction(C_label_list):\n",
    "    P_of_C_dic = get_conjunction(P_address, C_address_list, C_label_list)\n",
    "    return [C_address_list[0], P_of_C_dic]\n",
    "\n",
    "  if has_same_phrase_type(head_C_label_list):\n",
    "    if (('Cp' in C_label_list) or ('CONJP' in C_label_list)) and (C_label_list[0] != 'Cp') and (C_label_list[0] != 'CONJP'):\n",
    "      P_of_C_dic = get_conjunction(P_address, C_address_list, C_label_list)\n",
    "      return [C_address_list[0], P_of_C_dic]\n",
    "    else:\n",
    "      first_element = head_C_address_list[0]\n",
    "      if first_element[-1] >= 1:\n",
    "        pre_address_of_head_C_address_list = first_element[:-1] + [first_element[-1]-1] \n",
    "        pre_subtree = get_subtree(pre_address_of_head_C_address_list, tree)\n",
    "        pre_subtree_label = pre_subtree.label()\n",
    "        if re.search('^(Cp|CONJP)', pre_subtree_label):\n",
    "          P_of_C_dic = get_conjunction(P_address, C_address_list, C_label_list)\n",
    "          return [C_address_list[0], P_of_C_dic]\n",
    "\n",
    "    for head_C_address, head_C_label in zip(head_C_address_list, head_C_label_list):\n",
    "      if '-' not in head_C_label:\n",
    "        return [head_C_address]\n",
    "\n",
    "    for head_C_address, head_C_label in zip(head_C_address_list, head_C_label_list):\n",
    "      if '-SBJ' not in head_C_label:\n",
    "        return [head_C_address]\n",
    "  else:\n",
    "    if ('Cp' in C_label_list) and (C_label_list[0] != 'Cp'):\n",
    "      P_of_C_dic = get_conjunction(P_address, C_address_list, C_label_list)\n",
    "      return [C_address_list[0], P_of_C_dic]\n",
    "\n",
    "    else:\n",
    "      P_phrase_type = get_subtree(P_address, tree).label().split('-')[0]\n",
    "      head_exception_rules = {\n",
    "          \"NP\":[\"^(Nn_swsp|Nn_w)(-|$)\",\"^(Nn|Nu|Nun|Nt)(-|$)\",\"^(Num|Nq|Nr)(-|$)\"],\n",
    "          \"QP\":[\"^Nq(-|$)\",\"^Num(-|$)\"],\n",
    "          \"Nn_swsp\":[\"^(Ncs|Nc)(-|$)\"],\n",
    "          \"VP\":[\"^(Ve|Vc|D|Vcp|Vv)(-|$)\"],\n",
    "          \"S\":[\"^(S|SQ)($)\"],\n",
    "          \"SBAR\":[\"^(S|SQ)($)\"]\n",
    "\n",
    "      }\n",
    "\n",
    "      for rule in head_exception_rules[P_phrase_type]:\n",
    "              for head_C_address, head_C_label  in zip(head_C_address_list, head_C_label_list):\n",
    "                if is_head(rule, head_C_label):\n",
    "                  return [head_C_address]\n",
    "  return \"Nope\"      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "e9V2zeNIxeH1"
   },
   "outputs": [],
   "source": [
    "# Trả về list các phrase có chung headword\n",
    "def from_phrase_to_headword(mother_tree, tree, tree_address):\n",
    "  phrase_to_headword = [tree_address]\n",
    "  if tree_address != 'root':\n",
    "    tree = get_subtree(tree_address, mother_tree)\n",
    "  P_of_C_dic = {}\n",
    "  while type(tree[0]) != str:\n",
    "      head_index_list, head_label_list = finding_head_of_tree(tree)\n",
    "      \n",
    "      \n",
    "      if len(head_index_list) == 1:\n",
    "        if tree_address != 'root':\n",
    "          tree_address = tree_address + head_index_list[0]\n",
    "        else:\n",
    "          tree_address = head_index_list[0]\n",
    "        tree = get_subtree(tree_address, mother_tree)\n",
    "        phrase_to_headword.append(tree_address)\n",
    "      else:   \n",
    "        address_list, label_list = deepen_head_list(mother_tree, tree_address, head_index_list)\n",
    "        head_address_list = []\n",
    "        for head_index in head_index_list:\n",
    "          if tree_address != 'root':\n",
    "            head_address_list.append(tree_address + head_index)\n",
    "          else:\n",
    "            head_address_list.append(head_index)\n",
    "        result = identify_head(mother_tree, tree_address, address_list, label_list, head_address_list, head_label_list)\n",
    "        tree_address = result[0]#tree, P_address, C_address_list, C_label_list, head_C_address_list, head_C_label_list\n",
    "        tree = get_subtree(tree_address, mother_tree)\n",
    "        \n",
    "        phrase_to_headword.append(tree_address)\n",
    "        if len(result) == 2:\n",
    "          P_of_C_dic.update(result[1])  \n",
    "  phrase_to_headword.append(tree[0])\n",
    "  return [phrase_to_headword, P_of_C_dic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fK9pgpDnxipk"
   },
   "outputs": [],
   "source": [
    "def assign_headword_for_phrase(tree):\n",
    "\n",
    "  P_of_C_dic = {}\n",
    "  headword_of_phrase = {}\n",
    "  phrase_address_list = ['root'] + get_all_subtree_address(tree)\n",
    "  \n",
    "  #Tìm head\n",
    "  for phrase_address in phrase_address_list:\n",
    "    if str(phrase_address) not in headword_of_phrase:\n",
    "      if phrase_address != 'root': \n",
    "        subtree = get_subtree(phrase_address, tree)\n",
    "      else:    \n",
    "        subtree = tree\n",
    "      if type(subtree[0]) != str:\n",
    "        result = from_phrase_to_headword(tree, subtree, phrase_address)       \n",
    "        phrase_to_headword = result[0][:-1]\n",
    "        headword = result[0][-1] \n",
    "        P_of_C_dic.update(result[1])\n",
    "        for head_phrase_address in phrase_to_headword:\n",
    "          headword_of_phrase[str(head_phrase_address)] = headword\n",
    "      else:\n",
    "        headword_of_phrase[str(phrase_address)] = subtree[0]\n",
    "\n",
    "  for phrase_address in get_all_subtree_address(tree):\n",
    "    subtree = get_subtree(phrase_address, tree)\n",
    "    label = subtree.label().split('-')[0]\n",
    "    if label == 'UCP':\n",
    "      C_address_list = []\n",
    "      C_label_list = []\n",
    "      for index_subtree in range(len(subtree)):\n",
    "        subtree_address = phrase_address+[index_subtree]\n",
    "        subtree_label = get_subtree(subtree_address, tree).label() \n",
    "        C_address_list.append(subtree_address)\n",
    "        C_label_list.append(subtree_label)\n",
    "      P_of_C_dic.update(get_conjunction(phrase_address, C_address_list, C_label_list))\n",
    "  return [headword_of_phrase, P_of_C_dic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeCyefMVeLnL"
   },
   "source": [
    "#4. Dán nhãn \n",
    "Các bước cụ thể:\n",
    "+ Bước 1: Xác định C(node cao nhất của headword) và P(node parent của C)\n",
    "+ Bước 2: Viết luật dán nhãn được suy ra từ label của C và P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-mifyOIfeXCy"
   },
   "outputs": [],
   "source": [
    "# Lấy C của word\n",
    "def get_C_of_headword(headword_of_phrase):\n",
    "  duplicate_headword_of_phrase = {}\n",
    "  duplicate_headword_of_phrase.update(headword_of_phrase)\n",
    "  del duplicate_headword_of_phrase['root']\n",
    "  merge = {}\n",
    "  for key, value in sorted(duplicate_headword_of_phrase.items()):\n",
    "      merge.setdefault(value, []).append(key)\n",
    "  C ={}\n",
    "  for headword in merge:\n",
    "    C[headword]=min(merge[headword], key=len)\n",
    "  return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Nx5F5gx8fUXa"
   },
   "outputs": [],
   "source": [
    "# Lấy P của C\n",
    "def get_P_of_C(phrase_address, root_address):\n",
    "  if not str_to_list(phrase_address)[:-1]:\n",
    "    return root_address\n",
    "  return str(str_to_list(phrase_address)[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "F55gILhPfVyC"
   },
   "outputs": [],
   "source": [
    "# Dán nhãn dựa trên các Luật\n",
    "def get_dependency_relation(P_address, C_address, P_index, tree):\n",
    "  #get C_label and P_label\n",
    "  C_tree = get_subtree(C_address, tree)\n",
    "  C = C_tree.label()\n",
    "  P = get_subtree(P_address, tree).label()\n",
    "  \n",
    "  POS_of_word = get_POS_of_word(tree)\n",
    "  p = POS_of_word[P_index]\n",
    "  # Nếu C là UCP thì relation sẽ đc quyết bởi POS trái nhất trong cây UCP\n",
    "  if 'UCP' in C:\n",
    "    C = C_tree[0].label()\n",
    "\n",
    "  #Luật\n",
    "  if has_SBJ(C):\n",
    "    return has_SBJ(C)\n",
    "  \n",
    "  if is_ADJUNCT(C):\n",
    "    return is_ADJUNCT(C)\n",
    "  \n",
    "  if is_PARATAXIS(C):\n",
    "    return is_PARATAXIS(C)\n",
    "  \n",
    "  if is_VOCATIVE(C):\n",
    "    return is_VOCATIVE(C)\n",
    "\n",
    "  if is_NP_ADVMOD(P, C):\n",
    "    return is_NP_ADVMOD(P, C)\n",
    "\n",
    "  if is_ADJP_ADVMOD(P, C):\n",
    "    return is_ADJP_ADVMOD(P, C)\n",
    "\n",
    "  if is_VMOD_or_RCMOD(P, C):\n",
    "    return is_VMOD_or_RCMOD(P, C)\n",
    "\n",
    "  if is_NUM(P, C):\n",
    "    return is_NUM(P, C)\n",
    "\n",
    "  if is_NN(P, C):\n",
    "    return is_NN(P, C)\n",
    "\n",
    "  if is_PREP(C):\n",
    "    return is_PREP(C)\n",
    "  \n",
    "  if is_POBJ_or_PCOMP(P, C):\n",
    "    return is_POBJ_or_PCOMP(P, C)\n",
    "    \n",
    "  if is_PUNCT(C):\n",
    "    return is_PUNCT(C)\n",
    "\n",
    "  if is_CLF_or_NN(P, p):\n",
    "    return is_CLF_or_NN(P, p)\n",
    "\n",
    "  if is_AMOD(P, C):\n",
    "    return is_AMOD(P, C)\n",
    "  \n",
    "  if is_NUMBER_or_QUANTMOD(P, C):\n",
    "    return is_NUMBER_or_QUANTMOD(P, C)\n",
    "  \n",
    "  if is_NN(P, C):\n",
    "    return is_NN(P, C)\n",
    "  \n",
    "  if is_DET(P, C):\n",
    "    return is_DET(P, C)\n",
    "\n",
    "  if is_ATTR(p, C):\n",
    "    return is_ATTR(p, C)\n",
    "\n",
    "  if is_IOBJ(P, C):\n",
    "    return is_IOBJ(P, C)\n",
    "  \n",
    "  if is_OBJ_or_NP_ADVMOD(P, C):\n",
    "    return is_OBJ_or_NP_ADVMOD(P, C)\n",
    "\n",
    "  if is_CCOMP_or_XCOMP_or_ADVCL(P, C, C_tree):\n",
    "    return is_CCOMP_or_XCOMP_or_ADVCL(P, C, C_tree)\n",
    "  \n",
    "  if is_ACOMP(P, C):\n",
    "    return is_ACOMP(P, C)\n",
    "  \n",
    "  if is_ADVCL(P, C):\n",
    "    return is_ADVCL(P, C)\n",
    "\n",
    "  if is_SINO(P):\n",
    "    return is_SINO(P)\n",
    "\n",
    "  if is_INTJ(C):\n",
    "    return is_INTJ(C)\n",
    "  \n",
    "  if is_CC(C):\n",
    "    return is_CC(C)\n",
    "\n",
    "  if is_MARK(C):\n",
    "    return is_MARK(C)\n",
    "#Luật phụ\n",
    "  if is_NSUBJ(C, P):\n",
    "    return is_NSUBJ(C, P)\n",
    "\n",
    "  return 'DEP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdNGzc8zfiLj"
   },
   "source": [
    "## Các luật chuyển đổi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Agop9uJ-fv6S"
   },
   "outputs": [],
   "source": [
    "# Hàm dùng để xác định xem  coi S có chủ ngữ không để suy ra CCOMP or XCOMP\n",
    "def has_empty_subject(tree):\n",
    "  if 'SBAR' in tree.label():\n",
    "    for subtree in tree:\n",
    "      if re.search('^S(-|$)', subtree.label()):\n",
    "        for sub_subtree in subtree:\n",
    "          if 'NP-SBJ' in sub_subtree.label() and 'NONE' in sub_subtree[0].label():\n",
    "            return True\n",
    "        return False\n",
    "    return False \n",
    "  elif re.search('^S(-|$)', tree.label()):\n",
    "    for subtree in tree:\n",
    "      if 'NP-SBJ' in subtree.label() and 'NONE' in subtree[0].label():\n",
    "        return True\n",
    "    return False\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "seHZc3CYf6Ub"
   },
   "outputs": [],
   "source": [
    "# Hàm dùng để xem coi cây có thành phần POS mà mình muốn hay không\n",
    "# Ví dụ xét coi cây có nhãn VP để suy ra CCOMP or XCOMP\n",
    "def has_POS(tree, POS):\n",
    "  if 'SBAR' in tree.label():\n",
    "    for subtree in tree:\n",
    "      if re.search('^S(-|$)', subtree.label()):\n",
    "        for sub_subtree in subtree:\n",
    "          label_sub_subtree = sub_subtree.label()\n",
    "          if re.search('^{}(-|$)'.format(POS), label_sub_subtree):\n",
    "            return True\n",
    "        return False\n",
    "    return False \n",
    "\n",
    "  elif re.search('^S(-|$)', tree.label()):\n",
    "    for subtree in tree:\n",
    "      label_subtree = subtree.label()\n",
    "      if re.search('^{}(-|$)'.format(POS), label_subtree):\n",
    "        return True\n",
    "    return False\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "GsjvTF3Vf-4q"
   },
   "outputs": [],
   "source": [
    "#S(-|$) phân biệt vs SBAR\n",
    "def has_SBJ(C):\n",
    "  if 'NP-SBJ' in C:\n",
    "    return 'NSUBJ'\n",
    "  elif 'ADJP-SBJ' in C:\n",
    "    return 'ASUBJ'\n",
    "  elif 'VP-SBJ' in C:\n",
    "    return 'VSUBJ'\n",
    "  elif ('S-SBJ' in C) or ('SPL-SBJ' in C):\n",
    "    return 'CSUBJ'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_NSUBJ(C, P):\n",
    "  if re.search('^S$', P) and re.search('^NP$', C):\n",
    "    return 'NSUBJ'\n",
    "  else:\n",
    "    return False\n",
    "# def is_VMOD_or_RCMOD(P, C):#Ve|Vc|D|Vcp|Vv\n",
    "#   if re.search('^(VP)', C):\n",
    "#     if re.search('^(VP|ADJP|S)', P):\n",
    "#       return 'VMOD'\n",
    "#     elif re.search('^(NP|QNP)', P):\n",
    "#       return 'RCMOD'\n",
    "#     else:\n",
    "#       return False\n",
    "#   elif re.search('^(NP)', P) and re.search('^(Vv)', C) :\n",
    "#     return 'VMOD'\n",
    "#   else:\n",
    "#     return False\n",
    "\n",
    "def is_VMOD_or_RCMOD(P, C):#Ve|Vc|D|Vcp|Vv\n",
    "  if re.search('^(VP|ADJP|S)', P):\n",
    "    if re.search('^(VP|Ve|Vc|D|Vcp|Vv)', C):\n",
    "      return 'VMOD'\n",
    "    else:\n",
    "      return False\n",
    "  elif re.search('^(NP|QNP)', P):\n",
    "    if re.search('^(VP)', C):\n",
    "      return 'RCMOD'\n",
    "    elif re.search('^(Ve|Vc|D|Vcp|Vv)', C):\n",
    "      return 'VMOD'\n",
    "    else:\n",
    "      return False\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_NUM(P, C):\n",
    "  if re.search('^(NP|QNP|Nn)', P) and re.search('^(Num|QP)', C):\n",
    "    return 'NUM'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_NN(P, C):\n",
    "  if re.search('^(NP)', P) and re.search('^(NP|ID)', C):\n",
    "    return 'NN'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_PREP(C):\n",
    "  if re.search('^(PP|QPP)', C):\n",
    "    return 'PREP'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_POBJ_or_PCOMP(P, C):\n",
    "  if re.search('^(PP|QPP)', P):\n",
    "    if re.search('^(NP)', C):\n",
    "      return 'POBJ'\n",
    "    else:\n",
    "      return 'PCOMP'\n",
    "  else:\n",
    "    return False\n",
    "    \n",
    "def is_PUNCT(C):\n",
    "  if re.search('^(PU|LBRK|RBRK)', C):\n",
    "    return 'PUNCT'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_CLF_or_NN(P, p):\n",
    "  if re.search('^(Nn_swsp)', P):\n",
    "    if re.search('^(Nc|Ncs)', p):\n",
    "      return 'CLF'\n",
    "    else:\n",
    "      return 'NN'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_AMOD(P, C):\n",
    "  if re.search('^(NP|QNP)', P) and re.search('^(Aa|An|ADJP)', C): \n",
    "    return 'AMOD'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_NUMBER_or_QUANTMOD(P, C):\n",
    "  if re.search('^(QP)', P):\n",
    "    if re.search('^(Num|Nq)', C):\n",
    "      return 'NUMBER'\n",
    "    else:\n",
    "      return 'QUANTMOD'\n",
    "  else: \n",
    "    return False \n",
    "\n",
    "def is_NN(P, C):\n",
    "  if re.search('^(NP|QNP)', P) and re.search('^(NP|Nr|Nt|Nu|Nun|Nn)', C):\n",
    "    return 'NN'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_DET(P, C):\n",
    "  if re.search('^(NP|QNP)', P) and re.search('^(Nw|Nq|Pd|Pp)', C):\n",
    "    return 'DET' \n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_ATTR(p, C):\n",
    "  if re.search('^(Vc)', p) and re.search('^(NP|QNP)(-CMP)', C):\n",
    "    return 'ATTR' \n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_IOBJ(P, C):\n",
    "  if re.search('^(VP)', P) and re.search('^(NP-IOB)', C):\n",
    "    return 'IOBJ'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_OBJ_or_NP_ADVMOD(P, C):\n",
    "  if re.search('^(VP)', P) and re.search('^(NP)(-MNR)', C):\n",
    "    return 'NP_ADVMOD'\n",
    "  elif (re.search('^(VP|ADJP)', P) and re.search('^(NP|QNP|Nn)', C)) or ('-DOB' in C):\n",
    "    return 'OBJ'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_CCOMP_or_XCOMP_or_ADVCL(P, C, C_tree):\n",
    "  # if re.search('^(NP)', P):  \n",
    "  #   if re.search('^(S)(-CMP|$)', C): # phân biệt SBAR\n",
    "  #     return 'CCOMP'\n",
    "  #   elif re.search('^(SBAR)(-CMP|$)', C) and C_tree[0].label() == 'Cs':\n",
    "  #     return 'CCOMP'\n",
    "  #   else:\n",
    "  #     return 'False'\n",
    "  if re.search('^(VP|NP|ADJP|SQ|S|QVP)', P):\n",
    "    if re.search('^(SQ|SPL)(-|$)', C):\n",
    "      return 'CCOMP'\n",
    "    elif re.search('^(S)(-[0-9]|-CMP|$)', C):\n",
    "      if has_empty_subject(C_tree) and has_POS(C_tree, 'VP'):\n",
    "        return 'XCOMP'\n",
    "      else:\n",
    "        return 'CCOMP'\n",
    "    elif re.search('^(SBAR)(-[0-9]|-CMP|$)', C):\n",
    "      if has_empty_subject(C_tree) and has_POS(C_tree, 'VP'):\n",
    "        return 'XCOMP'\n",
    "      else:\n",
    "        return 'CCOMP'\n",
    "    elif re.search('^(SBAR)(-PRP)', C):\n",
    "      return 'ADVCL'\n",
    "    else:\n",
    "      return False\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_ADJUNCT(C):\n",
    "  if re.search('^(R|RP|QRP)(-|$)', C):\n",
    "    return 'ADJUNCT'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_NP_ADVMOD(P, C):\n",
    "  if re.search('^((S)(-|$)|SPL|NP|ADJP|VP|SQ)', P) and re.search('^(NP)(-TMP|-MNR|-ADV|-LOC)', C):\n",
    "    return 'NP_ADVMOD'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_ADJP_ADVMOD(P, C):\n",
    "  if re.search('^(VP|S(-|$)|SPL)', P) and re.search('^(ADJP)(-MNR|-ADV|-TMP|-MDP|-LOC|-PRD)', C):\n",
    "      return 'ADJP_ADVMOD'\n",
    "  elif re.search('^(ADJP)', P) and re.search('^(ADJP)', C):\n",
    "    return 'ADJP_ADVMOD'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_ACOMP(P, C):\n",
    "  if re.search('^(VP)', P) and re.search('^(ADJP)(-CMP|$)', C):\n",
    "    return 'ACOMP'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_ADVCL(P, C):\n",
    "  if re.search('^(S)(-CND|-PRN|-TMP|-PRP|-ADV|-MNR|-CNC)', C):\n",
    "    return 'ADVCL'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_PARATAXIS(C):\n",
    "  if '-PRN'in C:\n",
    "    return 'PARATAXIS'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_SINO(P):\n",
    "  if '_w' in P:\n",
    "    return 'SINO'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_INTJ(C):\n",
    "  if re.search('^(E|M)', C):\n",
    "    return 'INTJ'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_CC(C):\n",
    "  if re.search('^(Cp|CONJP)', C):\n",
    "    return 'CC'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_MARK(C):\n",
    "  if C == 'Cs':\n",
    "    return 'MARK'\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def is_VOCATIVE(C):\n",
    "  if '-VOC'in C:\n",
    "    return 'VOCATIVE'\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-DGdi1Ng8iy"
   },
   "source": [
    "##Hàm main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "n9-OB4KLg-cq"
   },
   "outputs": [],
   "source": [
    "def get_all_relation(tree):\n",
    "  tree = from_word_to_number(tree)\n",
    "  \n",
    "  result = assign_headword_for_phrase(tree)\n",
    "\n",
    "  headword_of_phrase = result[0]\n",
    "  C_of_headword = get_C_of_headword(headword_of_phrase)\n",
    "  P_of_C = result[1]\n",
    "  relation_dic = {}\n",
    "  root_address = C_of_headword[headword_of_phrase['root']]\n",
    "  \n",
    "  P_index = '0'\n",
    "  relation = 'ROOT'\n",
    "  C_index = headword_of_phrase['root']\n",
    "  relation_dic[C_index] = [P_index, relation]\n",
    "  \n",
    "\n",
    "  for C_index in tree.leaves():\n",
    "    if C_index not in relation_dic:\n",
    "      C_address = C_of_headword[C_index]\n",
    "      if C_address in P_of_C:\n",
    "        P_address = P_of_C[C_address][0]\n",
    "        relation = P_of_C[C_address][1]\n",
    "        P_index = headword_of_phrase[P_address]\n",
    "        relation_dic[C_index] = [P_index, relation]\n",
    "      else:\n",
    "        P_address = get_P_of_C(C_address, root_address)\n",
    "        P_index = headword_of_phrase[P_address] \n",
    "        relation = get_dependency_relation(P_address, C_address, P_index, tree)\n",
    "        relation_dic[C_index] = [P_index, relation]\n",
    "  return relation_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NftWKhYfhd1K"
   },
   "source": [
    "#Hậu xử lý"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9zDv21Dh6kK"
   },
   "source": [
    "## Hàm tạo file thông dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "h0tG02rRhihz"
   },
   "outputs": [],
   "source": [
    "def to_oneline(filename):\n",
    "  with open(f'/content/{filename}.prd','r',encoding='utf8') as reader:\n",
    "    regex = r'(?<=<s>).+?(?=</s>)'\n",
    "    pattern = re.compile(regex,re.M|re.I|re.S)\n",
    "    data = reader.readlines()\n",
    "    data = ''.join(data)\n",
    "    sentences = re.findall(pattern=pattern,string=data)\n",
    "  with open(f'/content/lines_{filename}.prd','w',encoding='utf8') as writer:\n",
    "    for sentence in sentences:\n",
    "      writer.write(re.sub(re.compile('[\\s\\t\\n]+',re.I|re.M),' ',sentence).strip())\n",
    "      writer.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW9_FCYriGNZ"
   },
   "source": [
    "## Hàm thông dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bscZCGebiM0n"
   },
   "outputs": [],
   "source": [
    "# Trả về cây dependency (dạng list)\n",
    "def get_dependency_tree_list(filename):\n",
    "  with open(f'/content/lines_{filename}.prd','r',encoding='utf8') as reader:\n",
    "    lines = reader.readlines()\n",
    "  dependency_tree_list = []\n",
    "  for line in lines:\n",
    "    #print(filename, line)\n",
    "    dependency_tree = []\n",
    "    tree = Tree.fromstring(line)\n",
    "    original_tree = Tree.fromstring(line)\n",
    "    relations = get_all_relation(tree)\n",
    "    POS_tags = get_all_POS(tree)\n",
    "    function_tag_list = get_function_tag(tree)\n",
    "    for index, word in enumerate(original_tree.leaves()):\n",
    "      word_index = str(index+1)\n",
    "      head_index = relations[word_index][0]\n",
    "      relation = relations[word_index][1]\n",
    "      POS = POS_tags[index]\n",
    "      function_tag = function_tag_list[word_index]\n",
    "      dependency_tree.append([word_index, word, '_', POS, '_', function_tag, head_index, relation,'_','_'])\n",
    "    dependency_tree_list.append(dependency_tree)\n",
    "  return dependency_tree_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Mp0RSgUiuIg"
   },
   "source": [
    "## Thêm second relation\n",
    "+ Nguyên nhân: một số nhãn NULL có index refer tới các phrase nên khi khử nhãn NULL -> sửa các relaiton mà chỉ đến  NULL sang chỉ đến phrase mà NULL đề cập tới nhưng làm vậy là sai vì một phrase chỉ được phép nhận 1 head nên việc sửa này được coi là 1 đặc trưng phụ(second relation)\n",
    "+ Các bước: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Zcw5zPY5i0CA"
   },
   "outputs": [],
   "source": [
    "# Lấy các label có index\n",
    "def get_phrase_contain_index(tree):\n",
    "  phrase_index_list = []\n",
    "  phrase_address_list = get_all_subtree_address(tree)\n",
    "  for phrase_address in phrase_address_list:\n",
    "    subtree_label = get_subtree(phrase_address, tree).label()\n",
    "    if re.search('[0-9]$', subtree_label):\n",
    "      phrase_type = subtree_label.split('-')[0]\n",
    "      index = subtree_label.split('-')[-1]\n",
    "      phrase_index = phrase_type + '-' + index\n",
    "      phrase_index_list.append((phrase_address, phrase_index))\n",
    "\n",
    "  phrase_index_dic = dict()\n",
    "  for phrase_index, phrase_address in groupby(sorted(phrase_index_list, key = lambda ele: ele[1]), key = lambda ele: ele[1]):\n",
    "    phrase_index_dic[phrase_index] = [ele[0] for ele in phrase_address]\n",
    "  return phrase_index_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "VgJ4aZmQi4Ly"
   },
   "outputs": [],
   "source": [
    "# Lấy các vị trí của NULL-word trong câu\n",
    "def get_phrase_has_linked_NULL(tree):\n",
    "  word_list = tree.leaves()\n",
    "  tree = from_word_to_number(tree)\n",
    "  result = []\n",
    "  for word, leafPos in zip(word_list, tree.treepositions('leaves')):\n",
    "    if re.search('^\\*', word) and word[-1].isnumeric():\n",
    "      i = -1\n",
    "      index_word = tree[leafPos]\n",
    "      address = leafPos[:i]\n",
    "      POS = tree[address].label()\n",
    "      while (POS == 'NONE') or (not POS.isupper()):\n",
    "        i = i - 1\n",
    "        address = leafPos[:i]\n",
    "        POS = tree[address].label()\n",
    "      phrase_type = POS.split('-')[0]\n",
    "      NULL_index = word[-1]\n",
    "      phrase_index = phrase_type + '-' + NULL_index\n",
    "      result.append([index_word, phrase_index, list(address)])\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Y3BSOMZpi7y1"
   },
   "outputs": [],
   "source": [
    "# Trong trường hợp tìm mapping phrase cho NULLword mà có nhiều mapping phrase\n",
    "# Tính khoảng cách xem NULLword gần với mapping phrase nào nhất?\n",
    "def get_distance(phrase_address, map_address):\n",
    "  count = 0\n",
    "  for phrase_address_index, map_address_index in zip(phrase_address, map_address):\n",
    "    if phrase_address_index - map_address_index == 0:\n",
    "      count = count + 1\n",
    "    else:\n",
    "      return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "UnDcRTKCi_F5"
   },
   "outputs": [],
   "source": [
    "def find_map_phrase_address(phrase_of_NULL, map_phrase_list):\n",
    "  map_phrase_exception = {\n",
    "      'NP':'^(Nc|Ncs|Nu|Nun|Nt|Nq|Num|Nw|Nr|Nn)',\n",
    "      'VP':'^(Ve|Vc|D|Vcp|Vv)',\n",
    "      'ADJP':'^(An|Aa)',\n",
    "      'S':'^SQ'\n",
    "  }\n",
    "  phrase_index = phrase_of_NULL[1]\n",
    "  phrase_address = phrase_of_NULL[2]\n",
    "  for map_phrase, map_phrase_address in map_phrase_list.items():\n",
    "    if map_phrase == phrase_index:\n",
    "      if len(map_phrase_address) >=2:\n",
    "        distance = []\n",
    "        for address in map_phrase_address:\n",
    "          distance.append(get_distance(phrase_address, address))\n",
    "        selected_index = distance.index(max(distance))\n",
    "        return map_phrase_address[selected_index]\n",
    "      else:\n",
    "        return map_phrase_address[0]\n",
    "  \n",
    "  for map_phrase, map_phrase_address in map_phrase_list.items():\n",
    "    #print(phrase_index)\n",
    "    phrase_type = phrase_index.split('-')[0]\n",
    "    index_of_phrase = phrase_index.split('-')[1]\n",
    "    if re.search(map_phrase_exception[phrase_type], map_phrase) and map_phrase[-1] == index_of_phrase:\n",
    "      if len(map_phrase_address) >=2:\n",
    "        distance = []\n",
    "        for address in map_phrase_address:\n",
    "          distance.append(get_distance(phrase_address, address))\n",
    "        selected_index = distance.index(max(distance))\n",
    "        return map_phrase_address[selected_index]\n",
    "      else:\n",
    "        return map_phrase_address[0]\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "4k-r7ut2jAeg"
   },
   "outputs": [],
   "source": [
    "def add_second_relation(tree, dependency_tree, linked_NULL_list, map_phrase_list):\n",
    "  headword_of_phrase = assign_headword_for_phrase(tree)[0]\n",
    "  for linked_NULL in linked_NULL_list:\n",
    "    element = dependency_tree[int(linked_NULL[0])-1]\n",
    "    head_index = element[6]\n",
    "    relation = element[7]\n",
    "    map_phrase_address = find_map_phrase_address(linked_NULL, map_phrase_list)\n",
    "    if map_phrase_address != False:\n",
    "      map_index = headword_of_phrase[str(map_phrase_address)]\n",
    "      map_element = dependency_tree[int(map_index)-1]\n",
    "      second_dep = map_element[8]\n",
    "      if second_dep == '_':\n",
    "        map_element[8] = head_index + ':' + relation\n",
    "      else:\n",
    "        map_element[8] = map_element[8] + '|' + head_index + ':' + relation\n",
    "  return dependency_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "XGXYOUTTmJFQ"
   },
   "outputs": [],
   "source": [
    "# Đưa second_relation của NULL lên map phrase\n",
    "def edit_second_relation_of_NULL(tree, dependency_tree, linked_NULL_list, map_phrase_list):\n",
    "  headword_of_phrase = assign_headword_for_phrase(tree)[0]\n",
    "  for linked_NULL in linked_NULL_list:\n",
    "    element = dependency_tree[int(linked_NULL[0])-1]\n",
    "    head_index = element[6]\n",
    "    second_relation = element[8]\n",
    "    if second_relation != '_':\n",
    "      map_phrase_address = find_map_phrase_address(linked_NULL, map_phrase_list)\n",
    "      if map_phrase_address != False:\n",
    "        map_index = headword_of_phrase[str(map_phrase_address)]\n",
    "        map_element = dependency_tree[int(map_index)-1]\n",
    "        second_dep = map_element[8]\n",
    "        if second_dep == '_':\n",
    "          map_element[8] = second_relation\n",
    "        else:\n",
    "          map_element[8] = map_element[8] + '|' + second_relation\n",
    "  return dependency_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEMeG1szmfYY"
   },
   "source": [
    "## Relink headNULL\n",
    "+ Nguyên nhân: do khi áp dụng luật chuyển đổi vô tình lấy nhãn NULL làm head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "21Sj8NdEmWPo"
   },
   "outputs": [],
   "source": [
    "# Lấy các mối quan hệ mà NULL làm head\n",
    "def get_dep_dic_of_NULL(dependency_tree):\n",
    "  dep_dic = {}\n",
    "  for element in dependency_tree:\n",
    "    word_index = element[0]\n",
    "    word = element[1]\n",
    "    NULL_pos = element[3]\n",
    "    NULL_head_index = element[6]\n",
    "    NULL_relation = element[7]\n",
    "    if re.search('^\\*', word):\n",
    "      dep_index_list = []\n",
    "      pos_list = []\n",
    "      word_list = []\n",
    "      for temp in dependency_tree:\n",
    "        dep_word_index = temp[0]\n",
    "        dep_word = temp[1]\n",
    "        pos_of_dep_word = temp[3]\n",
    "        head_index = temp[6]\n",
    "        if head_index == word_index :\n",
    "          dep_index_list.append(dep_word_index)\n",
    "          pos_list.append(pos_of_dep_word)\n",
    "          word_list.append(dep_word)\n",
    "      if dep_index_list:\n",
    "        dep_dic[word_index] = [NULL_pos, NULL_head_index, NULL_relation, dep_index_list, pos_list, word_list]\n",
    "  return dep_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "-rO30RXZmXp_"
   },
   "outputs": [],
   "source": [
    "# Chọn một từ mà có mối quan hệ với NULL và trong đó NULL làm head\n",
    "# Từ được chọn sẽ thay thế NULL làm head cho các mối quan hệ liên quan tới NULL\n",
    "def select_index(NULL_pos, dep_index_list, pos_list, word_list):\n",
    "  phrase_type_list = ['^(NP|Nc|Ncs|Nu|Nun|Nt|Nq|Num|Nw|Nr|Nn)', '^(VP|Ve|Vc|D|Vcp|Vv)', '^(ADJP|An|Aa)']\n",
    "  for phrase_type in phrase_type_list:\n",
    "    if re.search(phrase_type, NULL_pos):\n",
    "      for dep_index, pos, word in zip(dep_index_list, pos_list, word_list):\n",
    "        if (re.search(phrase_type, pos)) and ('*' not in word):\n",
    "          return dep_index\n",
    "  for dep_index, pos, word in zip(dep_index_list, pos_list, word_list):\n",
    "    if (pos != 'PU') and (pos != 'Cp') and (pos != 'Cs') and ('*' not in word):\n",
    "      return dep_index\n",
    "\n",
    "  for dep_index, pos, word in zip(dep_index_list, pos_list, word_list):\n",
    "    if (pos != 'PU') and ('*' not in word):\n",
    "      return dep_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Cm15sn_AmZgf"
   },
   "outputs": [],
   "source": [
    "def relink_head_NULL(dependency_tree):\n",
    "  head_NULL_dic = get_dep_dic_of_NULL(dependency_tree)\n",
    "  if head_NULL_dic:\n",
    "    for NULL_index, dep_list in head_NULL_dic.items():\n",
    "      NULL_pos = dep_list[0]\n",
    "      NULL_head_index = dep_list[1]\n",
    "      NULL_relation = dep_list[2]\n",
    "      dep_index_list = dep_list[3]\n",
    "      pos_list = dep_list[4]\n",
    "      word_list = dep_list[5]\n",
    "      if (len(word_list) == 1) and ('*' not in word_list[0]):\n",
    "        selected_index = dep_index_list[0]\n",
    "        selected_element = dependency_tree[int(selected_index)-1]\n",
    "        selected_element[6] = NULL_head_index\n",
    "        selected_element[7] = NULL_relation\n",
    "\n",
    "        for element in dependency_tree:\n",
    "          second_relation_field = element[8]\n",
    "          second_relation_list = second_relation_field.split('|')\n",
    "          second_relation_list = [ selected_index +':'+second_relation.split(':')[1] if second_relation.split(':')[0] == NULL_index else second_relation for second_relation in second_relation_list] \n",
    "          element[8] = '|'.join(second_relation_list)\n",
    "\n",
    "      elif len(word_list) >= 2:\n",
    "        selected_index = select_index(NULL_pos, dep_index_list, pos_list, word_list)\n",
    "        selected_element = dependency_tree[int(selected_index)-1]\n",
    "        selected_element[6] = NULL_head_index\n",
    "        selected_element[7] = NULL_relation\n",
    "\n",
    "        for element in dependency_tree:\n",
    "          head_index = element[6]\n",
    "          if head_index == NULL_index:\n",
    "            element[6] = selected_index\n",
    "\n",
    "          second_relation_field = element[8]\n",
    "          second_relation_list = second_relation_field.split('|')\n",
    "          second_relation_list = [ selected_index +':'+second_relation.split(':')[1] if second_relation.split(':')[0] == NULL_index else second_relation for second_relation in second_relation_list] \n",
    "          element[8] = '|'.join(second_relation_list)\n",
    "  return dependency_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omNBgM6qnV8_"
   },
   "source": [
    "##Khử nhãn NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "nm9lwnBenn8g"
   },
   "outputs": [],
   "source": [
    "def minus_1(start_index, end_index):\n",
    "  minus_1 = {}\n",
    "  for index in range(start_index, end_index+1):\n",
    "    minus_1[str(index)]=str(index-1)\n",
    "  #print(minus_1)\n",
    "  return minus_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "7VfwPGEan2Sw"
   },
   "outputs": [],
   "source": [
    "def map_index(tree_dependency, minus_1):\n",
    "\n",
    "  for relation in tree_dependency:\n",
    "    word_index = relation[0]\n",
    "    if word_index in minus_1:\n",
    "      relation[0] = minus_1[word_index]\n",
    "\n",
    "    head_index = relation[6]\n",
    "    if head_index in minus_1:\n",
    "      relation[6] = minus_1[head_index]\n",
    "\n",
    "    if relation[8] != '_':\n",
    "      new_second_dependency = []\n",
    "      second_dependency_element = relation[8]\n",
    "      second_dependency_list = second_dependency_element.split('|')\n",
    "      for second_dependency in second_dependency_list:\n",
    "        split_second_dependency = second_dependency.split(':')\n",
    "        number = split_second_dependency[0]\n",
    "        dep = split_second_dependency[1]\n",
    "        if number in minus_1:\n",
    "          second_dependency = minus_1[number] +':'+ dep\n",
    "        new_second_dependency.append(second_dependency)\n",
    "      relation[8] = '|'.join(new_second_dependency)\n",
    "\n",
    "  return tree_dependency\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "hOQuD4DMn4Bn"
   },
   "outputs": [],
   "source": [
    "def remove_NULL(tree_dependency):\n",
    "  #Xóa các second relation mà có head_index trong với head_index chính thức và index_word\n",
    "  for index, element in enumerate(tree_dependency):\n",
    "      index_word = index+1\n",
    "      head_index = element[6]\n",
    "      second_relation_field = element[8]\n",
    "      if second_relation_field != '_':\n",
    "        new_second_relation_list = []\n",
    "        second_relation_list = second_relation_field.split('|')\n",
    "        for second_relation in second_relation_list:\n",
    "          s_head_index = second_relation.split(':')[0]\n",
    "          if (s_head_index != str(index_word)) and (s_head_index != head_index):\n",
    "            new_second_relation_list.append(second_relation)\n",
    "        if new_second_relation_list:\n",
    "          element[8] = '|'.join(new_second_relation_list)\n",
    "        else:\n",
    "          element[8] = '_'\n",
    "\n",
    "  #Khử nhãn NULL\n",
    "  check_null_1 = True\n",
    "  while check_null_1:\n",
    "    for index, element in enumerate(tree_dependency):\n",
    "      check_null_2 = True\n",
    "      word = element[1]\n",
    "      index_word = index+1\n",
    "\n",
    "      if re.search('(^\\*)', word):\n",
    "        minus = minus_1(index_word+1, len(tree_dependency))\n",
    "        tree_dependency = map_index(tree_dependency, minus)\n",
    "        del tree_dependency[index]\n",
    "        check_null_2 = False\n",
    "        break\n",
    "    if check_null_2:\n",
    "      check_null_1 = False\n",
    "  return tree_dependency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhPNziFXoiQx"
   },
   "source": [
    "# Tạo file CONLLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "qGuV9x0Cok8o"
   },
   "outputs": [],
   "source": [
    "def finish_dependency_tree(filename, dependency_treebank):\n",
    "  with open(f'/content/lines_{filename}.prd','r',encoding='utf8') as reader:\n",
    "    lines = reader.readlines()\n",
    "  with open(f'/content/[Final]VnDep_{filename}.conllu','w',encoding='utf8') as writer:\n",
    "    tree_index = 1 \n",
    "    for line, dependency_tree in zip(lines, dependency_treebank):\n",
    "      print(filename,line)\n",
    "      tree = Tree.fromstring(line)\n",
    "      linked_NULL_list = get_phrase_has_linked_NULL(tree)\n",
    "      map_phrase_list = get_phrase_contain_index(tree)\n",
    "\n",
    "      new_dependency_tree = add_second_relation(tree, dependency_tree, linked_NULL_list, map_phrase_list)\n",
    "      edit_dependency_tree = edit_second_relation_of_NULL(tree, new_dependency_tree, linked_NULL_list, map_phrase_list)\n",
    "      relink_headNULL_dependency_tree = relink_head_NULL(edit_dependency_tree)\n",
    "      remove_NULL_dependency_tree = remove_NULL(relink_headNULL_dependency_tree)\n",
    "      \n",
    "      writer.write('# ID = {}\\n'.format(tree_index))\n",
    "      tree_index = tree_index + 1\n",
    "      for element in edit_dependency_tree:\n",
    "        writer.write('\\t'.join(element))\n",
    "        writer.write('\\n')\n",
    "      writer.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3Yl_k24o1L4",
    "outputId": "db6bc563-4634-4dc8-a7d3-a2976370439a"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "file_list = ['Dev_4784','Dev_25432','Dev_25480','Dev_25600','Dev_26554','Dev_46137','Dev_7105','Dev_7276','Dev_81347','Dev_90295','Dev_9539']\n",
    "dependency_treebank_list = []\n",
    "for file in file_list:\n",
    "  to_oneline(file)\n",
    "  dependency_treebank = get_dependency_tree_list(file)\n",
    "  finish_dependency_tree(file, dependency_treebank)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Consti_to_Depend.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
